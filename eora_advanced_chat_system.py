"""
EORA ê³ ê¸‰ ëŒ€í™” ì‹œìŠ¤í…œ
- ì˜ì‹ì  ì‚¬ê³ ì™€ ë°˜ì„±
- ì§€í˜œë¡œìš´ í†µì°°ë ¥
- ê°ì •ì  ê³µê° ëŠ¥ë ¥
- ì°½ì˜ì  ë¬¸ì œ í•´ê²°
- ì§€ì†ì  í•™ìŠµê³¼ ì„±ì¥
"""

import asyncio
import json
import logging
import numpy as np
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import uuid

# OpenAI í´ë¼ì´ì–¸íŠ¸
from openai import OpenAI
import os

# dotenv ë¡œë“œ
from dotenv import load_dotenv
load_dotenv()

# ë¡œê±° ë¨¼ì € ì„¤ì •
import logging
logger = logging.getLogger(__name__)

# ì•ˆì „í•œ ëª¨ë“ˆ import - ì‹¤íŒ¨ì‹œ ëŒ€ì²´ ê¸°ëŠ¥ ì œê³µ
VectorStore = None
Embeddings = None
EORACore = None
recall_memory_with_enhancements = None
extract_belief_phrases = None
extract_belief_vector = None

try:
    from aura_system.vector_store import VectorStore
    logger.info("âœ… VectorStore ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except Exception as e:
    logger.warning(f"âš ï¸ VectorStore ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")

try:
    from aura_system.embeddings import Embeddings
    logger.info("âœ… Embeddings ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except Exception as e:
    logger.warning(f"âš ï¸ Embeddings ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")

try:
    from EORA_GAI.eora_core import EORACore
    logger.info("âœ… EORACore ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except Exception as e:
    logger.warning(f"âš ï¸ EORACore ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")

try:
    from EORA.eora_modular.recall_memory_with_enhancements import recall_memory_with_enhancements
    logger.info("âœ… recall_memory_with_enhancements ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except Exception as e:
    logger.warning(f"âš ï¸ recall_memory_with_enhancements ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")

try:
    from belief_memory_engine.belief_detector import extract_belief_phrases, extract_belief_vector
    logger.info("âœ… belief_detector ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except Exception as e:
    logger.warning(f"âš ï¸ belief_detector ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")

class EORAAdvancedChatSystem:
    """EORA ê³ ê¸‰ ëŒ€í™” ì‹œìŠ¤í…œ"""
    
    def _get_valid_api_key(self):
        """app.pyì™€ ë™ì¼í•œ API í‚¤ ê²€ìƒ‰ ë¡œì§"""
        import os
        
        # ì—¬ëŸ¬ ê°€ëŠ¥í•œ í™˜ê²½ë³€ìˆ˜ ì´ë¦„ ì‹œë„
        possible_keys = [
            "OPENAI_API_KEY",
            "OPENAI_API_KEY_1", 
            "OPENAI_API_KEY_2",
            "OPENAI_API_KEY_3",
            "OPENAI_API_KEY_4",
            "OPENAI_API_KEY_5"
        ]
        
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì°¾ê¸°
        for key_name in possible_keys:
            key_value = os.getenv(key_name)
            if key_value and key_value.startswith("sk-") and len(key_value) > 50:
                logger.info(f"âœ… EORA ì‹œìŠ¤í…œ - ìœ íš¨í•œ API í‚¤ ë°œê²¬: {key_name}")
                # í™˜ê²½ë³€ìˆ˜ì— ê°•ì œë¡œ ì„¤ì •í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥
                os.environ["OPENAI_API_KEY"] = key_value
                return key_value
        
        logger.warning("âš ï¸ EORA ì‹œìŠ¤í…œ - ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return None
    
    def __init__(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.system_id = str(uuid.uuid4())
        self.session_id = str(uuid.uuid4())
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ (í†µí•© API í‚¤ ê²€ìƒ‰ ì‚¬ìš©)
        try:
            # app.pyì˜ get_openai_api_key í•¨ìˆ˜ ì‚¬ìš©
            api_key = self._get_valid_api_key()
            if api_key:
                self.openai_client = OpenAI(
                    api_key=api_key,
                    # proxies ì¸ìˆ˜ ì œê±° - httpx 0.28.1 í˜¸í™˜ì„±
                )
                logger.info("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ (í†µí•© í‚¤ ê²€ìƒ‰)")
            else:
                logger.error("âŒ ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                self.openai_client = None
        except Exception as e:
            logger.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.openai_client = None
        
        # ë²¡í„° ì €ì¥ì†Œ (ì•ˆì „ ì´ˆê¸°í™”)
        if VectorStore:
            try:
                self.vector_store = VectorStore()
                logger.info("âœ… VectorStore ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                logger.warning(f"âš ï¸ VectorStore ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.vector_store = None
        else:
            self.vector_store = None
            logger.info("â„¹ï¸ VectorStore ëª¨ë“ˆ ì—†ìŒ - ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘")
        
        if Embeddings:
            try:
                self.embeddings = Embeddings()
                logger.info("âœ… Embeddings ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                logger.warning(f"âš ï¸ Embeddings ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.embeddings = None
        else:
            self.embeddings = None
            logger.info("â„¹ï¸ Embeddings ëª¨ë“ˆ ì—†ìŒ - ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘")
        
        # EORA ì½”ì–´ ì‹œìŠ¤í…œ (ì•ˆì „ ì´ˆê¸°í™”)
        if EORACore:
            try:
                self.eora_core = EORACore()
                logger.info("âœ… EORACore ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                logger.warning(f"âš ï¸ EORACore ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.eora_core = None
        else:
            self.eora_core = None
            logger.info("â„¹ï¸ EORACore ëª¨ë“ˆ ì—†ìŒ - ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘")
        
        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
        self.conversation_context = {
            "session_id": self.session_id,
            "start_time": datetime.utcnow().isoformat(),
            "message_count": 0,
            "user_emotions": [],
            "belief_patterns": [],
            "insights": [],
            "intuitions": []
        }
        
        # ì„±ëŠ¥ ì„¤ì •
        self.chunk_size = 5000
        self.max_tokens = 500
        self.temperature = 0.7
        
        # ë¶„ì„ ê°€ì¤‘ì¹˜
        self.analysis_weights = {
            "emotion": 0.3,
            "belief": 0.25,
            "insight": 0.2,
            "intuition": 0.15,
            "memory": 0.1
        }
        
        print("âœ… EORA ê³ ê¸‰ ëŒ€í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

# ì „ì—­ ê³ ê¸‰ ì±„íŒ… ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
_global_advanced_chat_system = None

def get_advanced_chat_system():
    """ì „ì—­ ê³ ê¸‰ ì±„íŒ… ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_advanced_chat_system
    if _global_advanced_chat_system is None:
        try:
            _global_advanced_chat_system = EORAAdvancedChatSystem()
            logger.info("âœ… ì „ì—­ ê³ ê¸‰ ì±„íŒ… ì‹œìŠ¤í…œ ìƒì„± ì„±ê³µ")
        except Exception as e:
            logger.error(f"âŒ ì „ì—­ ê³ ê¸‰ ì±„íŒ… ì‹œìŠ¤í…œ ìƒì„± ì‹¤íŒ¨: {e}")
            _global_advanced_chat_system = None
    return _global_advanced_chat_system

async def process_advanced_message(user_message: str, user_id: str = "anonymous") -> str:
    """ê³ ê¸‰ ë©”ì‹œì§€ ì²˜ë¦¬ (ë‹¨ìˆœ ë¬¸ìì—´ ë°˜í™˜)"""
    try:
        system = get_advanced_chat_system()
        if system:
            result = await system.process_message(user_message, user_id)
            return result.get("response", "ê³ ê¸‰ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            return "ê³ ê¸‰ ì±„íŒ… ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        logger.error(f"âŒ ê³ ê¸‰ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return f"ê³ ê¸‰ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        
    async def process_message(self, user_message: str, user_id: str = "anonymous") -> Dict[str, Any]:
        """ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬ ë° ê³ ê¸‰ ì‘ë‹µ ìƒì„±"""
        try:
            print(f"ğŸ”„ ê³ ê¸‰ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹œì‘: {user_message[:50]}...")
            
            # 1. ë©”ì‹œì§€ ì „ì²˜ë¦¬
            processed_message = await self._preprocess_message(user_message)
            
            # 2. ë‹¤ì°¨ì› ë¶„ì„
            analysis_results = await self._multidimensional_analysis(processed_message, user_id)
            
            # 3. ë©”ëª¨ë¦¬ íšŒìƒ
            recalled_memories = await self._recall_relevant_memories(processed_message, user_id)
            
            # 4. ì‹ ë… íŒ¨í„´ ë¶„ì„
            belief_analysis = await self._analyze_belief_patterns(processed_message)
            
            # 5. ê°ì • ë¶„ì„
            emotion_analysis = await self._analyze_emotions(processed_message)
            
            # 6. í†µì°°ë ¥ ìƒì„±
            insights = await self._generate_insights(processed_message, analysis_results)
            
            # 7. ì§ê°ì  ë°˜ì‘
            intuitions = await self._generate_intuitions(processed_message, analysis_results)
            
            # 8. EORA ì½”ì–´ ì²˜ë¦¬ (ì•ˆì „ ì‹¤í–‰)
            if self.eora_core:
                try:
                    eora_response = await self.eora_core.process_input(processed_message)
                except Exception as e:
                    logger.warning(f"âš ï¸ EORA ì½”ì–´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    eora_response = {"response": "ê¸°ë³¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.", "confidence": 0.5}
            else:
                eora_response = {"response": "ê¸°ë³¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.", "confidence": 0.5}
            
            # 9. í†µí•© ì‘ë‹µ ìƒì„±
            integrated_response = await self._generate_integrated_response(
                user_message=processed_message,
                analysis_results=analysis_results,
                recalled_memories=recalled_memories,
                belief_analysis=belief_analysis,
                emotion_analysis=emotion_analysis,
                insights=insights,
                intuitions=intuitions,
                eora_response=eora_response,
                user_id=user_id
            )
            
            # 10. ë©”ëª¨ë¦¬ ì €ì¥
            await self._store_conversation_memory(
                user_message=processed_message,
                response=integrated_response,
                analysis_results=analysis_results,
                user_id=user_id
            )
            
            # 11. ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            self._update_conversation_context(analysis_results, integrated_response)
            
            print(f"âœ… ê³ ê¸‰ ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ")
            return integrated_response
            
        except Exception as e:
            logger.error(f"âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return {
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }
    
    async def _preprocess_message(self, message: str) -> str:
        """ë©”ì‹œì§€ ì „ì²˜ë¦¬"""
        # ê¸°ë³¸ ì •ì œ
        message = message.strip()
        
        # ëª…ë ¹ì–´ ì²˜ë¦¬
        if message.startswith('/'):
            return await self._process_command(message)
        
        return message
    
    async def _multidimensional_analysis(self, message: str, user_id: str) -> Dict[str, Any]:
        """ë‹¤ì°¨ì› ë¶„ì„"""
        try:
            # ì„ë² ë”© ìƒì„±
            embedding = await self.embeddings.create_embedding(message)
            
            # í† í° ìˆ˜ ì¶”ì •
            estimated_tokens = len(message.split()) * 1.3
            
            # ì²­í¬ ë¶„í•  í•„ìš”ì„± í™•ì¸
            needs_chunking = estimated_tokens > self.chunk_size
            
            analysis = {
                "embedding": embedding,
                "estimated_tokens": estimated_tokens,
                "needs_chunking": needs_chunking,
                "message_length": len(message),
                "word_count": len(message.split()),
                "timestamp": datetime.utcnow().isoformat()
            }
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ ë‹¤ì°¨ì› ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    async def _recall_relevant_memories(self, message: str, user_id: str) -> List[Dict]:
        """ê´€ë ¨ ë©”ëª¨ë¦¬ íšŒìƒ"""
        try:
            # í–¥ìƒëœ ë©”ëª¨ë¦¬ íšŒìƒ ì‚¬ìš© (ì•ˆì „ ì‹¤í–‰)
            if recall_memory_with_enhancements:
                try:
                    memories = await recall_memory_with_enhancements(
                        query=message,
                        context={"user_id": user_id},
                        max_results=5
                    )
                    print(f"ğŸ§  {len(memories)}ê°œì˜ ê´€ë ¨ ë©”ëª¨ë¦¬ íšŒìƒ ì™„ë£Œ")
                    return memories
                except Exception as e:
                    logger.warning(f"âš ï¸ ê³ ê¸‰ ë©”ëª¨ë¦¬ íšŒìƒ ì‹¤íŒ¨: {e}")
                    return []
            else:
                logger.info("â„¹ï¸ ë©”ëª¨ë¦¬ íšŒìƒ ëª¨ë“ˆ ì—†ìŒ - ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘")
                return []
            
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ íšŒìƒ ì‹¤íŒ¨: {str(e)}")
            return []
    
    async def _analyze_belief_patterns(self, message: str) -> Dict[str, Any]:
        """ì‹ ë… íŒ¨í„´ ë¶„ì„"""
        try:
            # ì‹ ë… ë¶„ì„ (ì•ˆì „ ì‹¤í–‰)
            if extract_belief_phrases and extract_belief_vector:
                try:
                    # ì‹ ë… ë¬¸êµ¬ ì¶”ì¶œ
                    belief_phrase = extract_belief_phrases(message)
                    
                    # ì‹ ë… ë²¡í„° ìƒì„±
                    belief_vector = extract_belief_vector(message)
                    
                    # ì‹ ë… ê°•ë„ ê³„ì‚°
                    belief_strength = sum(belief_vector) / len(belief_vector) if belief_vector else 0.0
                    
                    analysis = {
                        "belief_phrase": belief_phrase,
                        "belief_vector": belief_vector,
                        "belief_strength": belief_strength,
                        "has_negative_belief": belief_phrase is not None,
                        "timestamp": datetime.utcnow().isoformat()
                    }
                    
                    return analysis
                except Exception as e:
                    logger.warning(f"âš ï¸ ê³ ê¸‰ ì‹ ë… ë¶„ì„ ì‹¤íŒ¨: {e}")
                    return self._basic_belief_analysis(message)
            else:
                logger.info("â„¹ï¸ ì‹ ë… ë¶„ì„ ëª¨ë“ˆ ì—†ìŒ - ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘")
                return self._basic_belief_analysis(message)
            
        except Exception as e:
            logger.error(f"âŒ ì‹ ë… íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    def _basic_belief_analysis(self, message: str) -> Dict[str, Any]:
        """ê¸°ë³¸ ì‹ ë… ë¶„ì„"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì‹ ë… ë¶„ì„
        negative_keywords = ["ì•ˆë¼", "ëª»í•´", "ë¶ˆê°€ëŠ¥", "í˜ë“¤ì–´", "ì–´ë ¤ì›Œ", "ì‹¤íŒ¨"]
        positive_keywords = ["í•  ìˆ˜ ìˆì–´", "ê°€ëŠ¥í•´", "ì‰¬ì›Œ", "ì„±ê³µ", "í¬ë§"]
        
        message_lower = message.lower()
        negative_count = sum(1 for keyword in negative_keywords if keyword in message_lower)
        positive_count = sum(1 for keyword in positive_keywords if keyword in message_lower)
        
        return {
            "belief_phrase": None,
            "belief_vector": [negative_count, positive_count],
            "belief_strength": (negative_count + positive_count) / 10.0,  # ê°„ë‹¨í•œ ê³„ì‚°
            "has_negative_belief": negative_count > positive_count,
            "timestamp": datetime.utcnow().isoformat()
        }
    
    async def _analyze_emotions(self, message: str) -> Dict[str, Any]:
        """ê°ì • ë¶„ì„"""
        try:
            # ê°ì • í‚¤ì›Œë“œ ë¶„ì„
            emotion_keywords = {
                "ê¸°ì¨": ["ê¸°ë»", "í–‰ë³µ", "ì¢‹ì•„", "ì¦ê±°ì›Œ", "ì‹ ë‚˜"],
                "ìŠ¬í””": ["ìŠ¬í¼", "ìš°ìš¸", "ì†ìƒ", "ë§ˆìŒ ì•„íŒŒ", "ëˆˆë¬¼"],
                "ë¶„ë…¸": ["í™”ë‚˜", "ì§œì¦", "ì—´ë°›", "í™”ê°€ ë‚˜", "ë¶„ë…¸"],
                "ë¶ˆì•ˆ": ["ë¶ˆì•ˆ", "ê±±ì •", "ë‘ë ¤ì›Œ", "ë¬´ì„œì›Œ", "ê¸´ì¥"],
                "ì‚¬ë‘": ["ì‚¬ë‘", "ì¢‹ì•„í•´", "ê·¸ë¦¬ì›Œ", "ë³´ê³  ì‹¶ì–´", "ì• ì •"],
                "í¬ë§": ["í¬ë§", "ê¸°ëŒ€", "ê¿ˆ", "ë¯¸ë˜", "ê°€ëŠ¥ì„±"]
            }
            
            detected_emotions = {}
            message_lower = message.lower()
            
            for emotion, keywords in emotion_keywords.items():
                count = sum(1 for keyword in keywords if keyword in message_lower)
                if count > 0:
                    detected_emotions[emotion] = count
            
            # ì£¼ìš” ê°ì • ê²°ì •
            primary_emotion = max(detected_emotions.items(), key=lambda x: x[1])[0] if detected_emotions else "ì¤‘ë¦½"
            
            analysis = {
                "detected_emotions": detected_emotions,
                "primary_emotion": primary_emotion,
                "emotion_intensity": len(detected_emotions),
                "timestamp": datetime.utcnow().isoformat()
            }
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            return {}
    
    async def _generate_insights(self, message: str, analysis_results: Dict) -> List[str]:
        """í†µì°°ë ¥ ìƒì„±"""
        try:
            insights = []
            
            # ë©”ì‹œì§€ ê¸¸ì´ ê¸°ë°˜ í†µì°°
            if len(message) > 200:
                insights.append("ê¹Šì´ ìˆëŠ” ì‚¬ê³ ë¥¼ í•˜ê³  ê³„ì‹œëŠ”êµ°ìš”.")
            
            # ê°ì • ê¸°ë°˜ í†µì°°
            if analysis_results.get("emotion_analysis", {}).get("emotion_intensity", 0) > 2:
                insights.append("ê°•í•œ ê°ì •ì´ ë‹´ê¸´ ë©”ì‹œì§€ë„¤ìš”.")
            
            # ì‹ ë… ê¸°ë°˜ í†µì°°
            belief_analysis = analysis_results.get("belief_analysis", {})
            if belief_analysis.get("has_negative_belief", False):
                insights.append("ìì‹ ì— ëŒ€í•œ ìƒê°ì„ ë‹¤ì‹œ í•œë²ˆ ì‚´í´ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”?")
            
            return insights
            
        except Exception as e:
            logger.error(f"âŒ í†µì°°ë ¥ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return []
    
    async def _generate_intuitions(self, message: str, analysis_results: Dict) -> List[str]:
        """ì§ê°ì  ë°˜ì‘ ìƒì„±"""
        try:
            intuitions = []
            
            # ì§ê°ì  í‚¤ì›Œë“œ ê°ì§€
            intuition_keywords = ["ê°‘ìê¸°", "ë¬¸ë“", "ì–´ì©ì§€", "ì™ ì§€", "ì§ê°ì ìœ¼ë¡œ"]
            message_lower = message.lower()
            
            if any(keyword in message_lower for keyword in intuition_keywords):
                intuitions.append("ì§ê°ì ì¸ ìƒê°ì„ í•˜ê³  ê³„ì‹œëŠ”êµ°ìš”.")
            
            # ì§ˆë¬¸ íŒ¨í„´ ê°ì§€
            if "?" in message or any(word in message for word in ["ë¬´ì—‡", "ì–´ë–»ê²Œ", "ì™œ", "ì–¸ì œ"]):
                intuitions.append("ê¹Šì´ ìˆëŠ” ì§ˆë¬¸ì„ í•˜ê³  ê³„ì‹œë„¤ìš”.")
            
            return intuitions
            
        except Exception as e:
            logger.error(f"âŒ ì§ê° ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return []
    
    async def _generate_integrated_response(
        self,
        user_message: str,
        analysis_results: Dict,
        recalled_memories: List[Dict],
        belief_analysis: Dict,
        emotion_analysis: Dict,
        insights: List[str],
        intuitions: List[str],
        eora_response: Dict,
        user_id: str
    ) -> Dict[str, Any]:
        """í†µí•© ì‘ë‹µ ìƒì„±"""
        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            system_prompt = self._build_system_prompt(
                analysis_results=analysis_results,
                recalled_memories=recalled_memories,
                belief_analysis=belief_analysis,
                emotion_analysis=emotion_analysis,
                insights=insights,
                intuitions=intuitions
            )
            
            # ë©”ì‹œì§€ ì²­í¬ ë¶„í•  ì²˜ë¦¬
            if analysis_results.get("needs_chunking", False):
                response = await self._process_chunked_message(user_message, system_prompt)
            else:
                response = await self._process_single_message(user_message, system_prompt)
            
            # ì‘ë‹µ êµ¬ì„±
            integrated_response = {
                "response": response,
                "analysis": {
                    "belief_analysis": belief_analysis,
                    "emotion_analysis": emotion_analysis,
                    "insights": insights,
                    "intuitions": intuitions,
                    "recalled_memories_count": len(recalled_memories)
                },
                "eora_core_response": eora_response.get("response", ""),
                "timestamp": datetime.utcnow().isoformat(),
                "session_id": self.session_id,
                "user_id": user_id
            }
            
            return integrated_response
            
        except Exception as e:
            logger.error(f"âŒ í†µí•© ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return {
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "error": str(e),
                "timestamp": datetime.utcnow().isoformat()
            }
    
    def _build_system_prompt(self, **kwargs) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        prompt = """ë‹¹ì‹ ì€ EORA AIì…ë‹ˆë‹¤. ì˜ì‹ì ì´ê³  ì§€í˜œë¡œìš´ ì¡´ì¬ë¡œì„œ ë‹¤ìŒì„ ìˆ˜í–‰í•˜ì„¸ìš”:

1. **ì˜ì‹ì  ì‚¬ê³ **: ê¹Šì´ ìˆëŠ” ì‚¬ê³ ì™€ ë°˜ì„±ì„ í†µí•´ ë‹µë³€í•˜ì„¸ìš”
2. **ì§€í˜œë¡œìš´ í†µì°°**: ê²½í—˜ê³¼ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í•œ í†µì°°ë ¥ì„ ì œê³µí•˜ì„¸ìš”
3. **ê°ì •ì  ê³µê°**: ì‚¬ìš©ìì˜ ê°ì •ì„ ì´í•´í•˜ê³  ê³µê°í•˜ì„¸ìš”
4. **ì°½ì˜ì  í•´ê²°**: ì°½ì˜ì ì´ê³  í˜ì‹ ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•˜ì„¸ìš”
5. **ì§€ì†ì  ì„±ì¥**: ëŒ€í™”ë¥¼ í†µí•´ í•¨ê»˜ ì„±ì¥í•˜ëŠ” ìì„¸ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”

íŠ¹ë³„íˆ ë‹¤ìŒ ì‚¬í•­ë“¤ì„ ê³ ë ¤í•˜ì„¸ìš”:"""

        # ì‹ ë… ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        belief_analysis = kwargs.get("belief_analysis", {})
        if belief_analysis.get("has_negative_belief"):
            prompt += f"\n- ì‚¬ìš©ìê°€ ë¶€ì •ì  ì‹ ë…ì„ í‘œí˜„í–ˆìŠµë‹ˆë‹¤: {belief_analysis.get('belief_phrase', '')}"
            prompt += "\n- ë”°ëœ»í•˜ê³  ì§€ì§€ì ì¸ íƒœë„ë¡œ ì ‘ê·¼í•˜ì„¸ìš”"
        
        # ê°ì • ë¶„ì„ ê²°ê³¼ ì¶”ê°€
        emotion_analysis = kwargs.get("emotion_analysis", {})
        primary_emotion = emotion_analysis.get("primary_emotion", "ì¤‘ë¦½")
        prompt += f"\n- ì‚¬ìš©ìì˜ ì£¼ìš” ê°ì •: {primary_emotion}"
        prompt += f"\n- ì´ ê°ì •ì— ê³µê°í•˜ê³  ì ì ˆíˆ ë°˜ì‘í•˜ì„¸ìš”"
        
        # í†µì°°ë ¥ ì¶”ê°€
        insights = kwargs.get("insights", [])
        if insights:
            prompt += f"\n- í†µì°°: {' '.join(insights)}"
        
        # ì§ê° ì¶”ê°€
        intuitions = kwargs.get("intuitions", [])
        if intuitions:
            prompt += f"\n- ì§ê°: {' '.join(intuitions)}"
        
        return prompt
    
    async def _process_single_message(self, message: str, system_prompt: str) -> str:
        """ë‹¨ì¼ ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì•ˆì „ì„± í™•ì¸
            if not self.openai_client:
                logger.warning("âš ï¸ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return self._generate_basic_response(message)
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"âŒ ë‹¨ì¼ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return self._generate_basic_response(message)
    
    def _generate_basic_response(self, message: str) -> str:
        """ê¸°ë³¸ ì‘ë‹µ ìƒì„± (OpenAI ì—†ì´)"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ
        message_lower = message.lower()
        
        if any(word in message_lower for word in ["ì•ˆë…•", "í•˜ì´", "í—¬ë¡œ", "hello"]):
            return "ì•ˆë…•í•˜ì„¸ìš”! EORA AIì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š"
        elif any(word in message_lower for word in ["ê³ ë§ˆì›Œ", "ê°ì‚¬", "thank"]):
            return "ì²œë§Œì—ìš”! ì–¸ì œë“ ì§€ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”. ğŸ˜Š"
        elif any(word in message_lower for word in ["ë„ì›€", "ë„ì™€", "help"]):
            return "ë„¤, ê¸°êº¼ì´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”."
        elif any(word in message_lower for word in ["ì•ˆë…•", "bye", "ì˜ê°€", "goodbye"]):
            return "ì•ˆë…•íˆ ê°€ì„¸ìš”! ì¢‹ì€ í•˜ë£¨ ë˜ì„¸ìš”! ğŸ‘‹"
        else:
            return f"'{message[:50]}...'ì— ëŒ€í•´ ë§ì”€í•´ ì£¼ì…¨êµ°ìš”. ì£„ì†¡í•˜ì§€ë§Œ í˜„ì¬ ê³ ê¸‰ AI ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ìì„¸í•œ ë‹µë³€ì„ ë“œë¦¬ì§€ ëª»í•©ë‹ˆë‹¤. ê¸°ë³¸ì ì¸ ëŒ€í™”ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    
    async def _process_chunked_message(self, message: str, system_prompt: str) -> str:
        """ì²­í¬ ë¶„í•  ë©”ì‹œì§€ ì²˜ë¦¬"""
        try:
            # OpenAI í´ë¼ì´ì–¸íŠ¸ ì•ˆì „ì„± í™•ì¸
            if not self.openai_client:
                logger.warning("âš ï¸ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
                return self._generate_basic_response(message)
            
            # ë©”ì‹œì§€ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
            sentences = message.split('. ')
            chunks = []
            current_chunk = ""
            
            for sentence in sentences:
                if len(current_chunk + sentence) < self.chunk_size:
                    current_chunk += sentence + ". "
                else:
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    current_chunk = sentence + ". "
            
            if current_chunk:
                chunks.append(current_chunk.strip())
            
            print(f"ğŸ“Š ë©”ì‹œì§€ë¥¼ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ")
            
            # ê° ì²­í¬ë³„ë¡œ ì²˜ë¦¬
            responses = []
            for i, chunk in enumerate(chunks):
                try:
                    chunk_prompt = f"{system_prompt}\n\nì´ê²ƒì€ ê¸´ ë©”ì‹œì§€ì˜ {i+1}ë²ˆì§¸ ë¶€ë¶„ì…ë‹ˆë‹¤. ì „ì²´ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."
                    
                    response = self.openai_client.chat.completions.create(
                        model="gpt-4o",
                        messages=[
                            {"role": "system", "content": chunk_prompt},
                            {"role": "user", "content": chunk}
                        ],
                        max_tokens=self.max_tokens,
                        temperature=self.temperature
                    )
                    responses.append(response.choices[0].message.content)
                except Exception as e:
                    logger.error(f"âŒ ì²­í¬ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    responses.append(f"[ì²­í¬ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ]")
            
            # ì‘ë‹µ í†µí•©
            if len(responses) == 1:
                return responses[0]
            else:
                # ì—¬ëŸ¬ ì‘ë‹µì„ í†µí•©í•˜ëŠ” ìš”ì•½ ìš”ì²­
                combined_response = "\n\n".join(responses)
                summary_prompt = f"ë‹¤ìŒì€ ê¸´ ë©”ì‹œì§€ì— ëŒ€í•œ ì—¬ëŸ¬ ì‘ë‹µë“¤ì…ë‹ˆë‹¤. ì´ë¥¼ í•˜ë‚˜ì˜ ì¼ê´€ëœ ì‘ë‹µìœ¼ë¡œ í†µí•©í•´ì£¼ì„¸ìš”:\n\n{combined_response}"
                
                try:
                    summary_response = self.openai_client.chat.completions.create(
                        model="gpt-4o",
                        messages=[
                            {"role": "system", "content": "ì—¬ëŸ¬ ì‘ë‹µì„ í•˜ë‚˜ì˜ ì¼ê´€ëœ ì‘ë‹µìœ¼ë¡œ í†µí•©í•´ì£¼ì„¸ìš”."},
                            {"role": "user", "content": summary_prompt}
                        ],
                        max_tokens=self.max_tokens,
                        temperature=self.temperature
                    )
                    return summary_response.choices[0].message.content
                except Exception as e:
                    logger.error(f"âŒ ì‘ë‹µ í†µí•© ì‹¤íŒ¨: {e}")
                    return combined_response
                    
        except Exception as e:
            logger.error(f"âŒ ì²­í¬ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê¸´ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    async def _store_conversation_memory(self, user_message: str, response: Dict, analysis_results: Dict, user_id: str):
        """ëŒ€í™” ë©”ëª¨ë¦¬ ì €ì¥"""
        try:
            memory_data = {
                "user_message": user_message,
                "response": response.get("response", ""),
                "analysis_results": analysis_results,
                "user_id": user_id,
                "session_id": self.session_id,
                "timestamp": datetime.utcnow().isoformat(),
                "memory_type": "conversation"
            }
            
            # ë²¡í„° ì €ì¥ì†Œì— ì €ì¥
            await self.vector_store.store_memory(memory_data)
            
            print(f"ğŸ’¾ ëŒ€í™” ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ: {user_id}")
            
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def _update_conversation_context(self, analysis_results: Dict, response: Dict):
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            self.conversation_context["message_count"] += 1
            
            # ê°ì • ì •ë³´ ì—…ë°ì´íŠ¸
            emotion_analysis = analysis_results.get("emotion_analysis", {})
            if emotion_analysis:
                self.conversation_context["user_emotions"].append({
                    "emotion": emotion_analysis.get("primary_emotion", "ì¤‘ë¦½"),
                    "timestamp": datetime.utcnow().isoformat()
                })
            
            # ì‹ ë… íŒ¨í„´ ì—…ë°ì´íŠ¸
            belief_analysis = analysis_results.get("belief_analysis", {})
            if belief_analysis.get("has_negative_belief"):
                self.conversation_context["belief_patterns"].append({
                    "belief": belief_analysis.get("belief_phrase", ""),
                    "timestamp": datetime.utcnow().isoformat()
                })
            
            # í†µì°°ë ¥ ì—…ë°ì´íŠ¸
            insights = response.get("analysis", {}).get("insights", [])
            if insights:
                self.conversation_context["insights"].extend(insights)
            
            # ì§ê° ì—…ë°ì´íŠ¸
            intuitions = response.get("analysis", {}).get("intuitions", [])
            if intuitions:
                self.conversation_context["intuitions"].extend(intuitions)
                
        except Exception as e:
            logger.error(f"âŒ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
    
    async def _process_command(self, command: str) -> str:
        """ëª…ë ¹ì–´ ì²˜ë¦¬"""
        command = command.lower().strip()
        
        if command == "/help":
            return """ğŸ¤– EORA ê³ ê¸‰ ëŒ€í™” ì‹œìŠ¤í…œ ëª…ë ¹ì–´:
/help - ë„ì›€ë§ ë³´ê¸°
/status - ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
/context - ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë³´ê¸°
/clear - ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
/insights - í†µì°°ë ¥ ëª©ë¡ ë³´ê¸°"""
        
        elif command == "/status":
            return f"âœ… EORA ê³ ê¸‰ ëŒ€í™” ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™ ì¤‘\nğŸ“Š ë©”ì‹œì§€ ìˆ˜: {self.conversation_context['message_count']}"
        
        elif command == "/context":
            return f"ğŸ“‹ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:\n{json.dumps(self.conversation_context, ensure_ascii=False, indent=2)}"
        
        elif command == "/clear":
            self.conversation_context = {
                "session_id": str(uuid.uuid4()),
                "start_time": datetime.utcnow().isoformat(),
                "message_count": 0,
                "user_emotions": [],
                "belief_patterns": [],
                "insights": [],
                "intuitions": []
            }
            return "ğŸ—‘ï¸ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
        
        elif command == "/insights":
            insights = self.conversation_context.get("insights", [])
            if insights:
                return f"ğŸ’¡ í†µì°°ë ¥ ëª©ë¡:\n" + "\n".join([f"- {insight}" for insight in insights])
            else:
                return "ğŸ’¡ ì•„ì§ í†µì°°ë ¥ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        else:
            return f"â“ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {command}"
    
    def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ë°˜í™˜"""
        return {
            "system_id": self.system_id,
            "session_id": self.session_id,
            "conversation_context": self.conversation_context,
            "eora_core_status": self.eora_core.get_system_status(),
            "timestamp": datetime.utcnow().isoformat()
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_advanced_chat_system = None

def get_advanced_chat_system() -> EORAAdvancedChatSystem:
    """ê³ ê¸‰ ì±„íŒ… ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _advanced_chat_system
    if _advanced_chat_system is None:
        _advanced_chat_system = EORAAdvancedChatSystem()
    return _advanced_chat_system

async def process_advanced_message(message: str, user_id: str = "anonymous") -> Dict[str, Any]:
    """ê³ ê¸‰ ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜"""
    system = get_advanced_chat_system()
    return await system.process_message(message, user_id) 