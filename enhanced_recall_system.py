#!/usr/bin/env python3
"""
í–¥ìƒëœ í•™ìŠµ ë°ì´í„° íšŒìƒ ì‹œìŠ¤í…œ
- ê°•í™”ëœ í•™ìŠµ ì‹œìŠ¤í…œê³¼ í˜¸í™˜
- ë‹¤ì–‘í•œ ê²€ìƒ‰ ì „ëµ ì§€ì›
- ì‚¬ìš©ìë³„ ê°œì¸í™”ëœ ê²°ê³¼
"""

import logging
import asyncio
from datetime import datetime
from typing import Dict, List, Optional, Any
from pymongo import MongoClient
from bson import ObjectId
import re

logger = logging.getLogger(__name__)

class EnhancedRecallSystem:
    """í–¥ìƒëœ í•™ìŠµ ë°ì´í„° íšŒìƒ ì‹œìŠ¤í…œ"""
    
    def __init__(self, mongo_client=None):
        self.mongo_client = mongo_client
        self.db = None
        if mongo_client:
            try:
                if hasattr(mongo_client, 'get_default_database'):
                    self.db = mongo_client.get_default_database()
                else:
                    self.db = mongo_client["eora_ai"]
            except Exception as e:
                logger.warning(f"ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨, eora_ai ì‚¬ìš©: {e}")
                self.db = mongo_client["eora_ai"]
    
    def is_connected(self) -> bool:
        """ì—°ê²° ìƒíƒœ í™•ì¸"""
        if self.mongo_client is None or self.db is None:
            return False
        try:
            self.mongo_client.admin.command('ping')
            return True
        except:
            return False
    
    async def recall_learning_data(self, 
                                 query: str, 
                                 user_id: str = None,
                                 memory_type: str = None,
                                 category: str = None,
                                 filename: str = None,
                                 limit: int = 5) -> List[Dict]:
        """
        í•™ìŠµëœ ë°ì´í„° íšŒìƒ (í†µí•© ê²€ìƒ‰)
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            user_id (str): ì‚¬ìš©ì ID (ê°œì¸í™”ìš©)
            memory_type (str): ë©”ëª¨ë¦¬ íƒ€ì… ('enhanced_learning', 'document_chunk' ë“±)
            category (str): ì¹´í…Œê³ ë¦¬ í•„í„°
            filename (str): íŒŒì¼ëª… í•„í„°
            limit (int): ê²°ê³¼ ì œí•œ
            
        Returns:
            List[Dict]: íšŒìƒëœ í•™ìŠµ ë°ì´í„° ëª©ë¡
        """
        if not self.is_connected():
            logger.warning("MongoDB ì—°ê²°ì´ ì—†ì–´ í•™ìŠµ ë°ì´í„° íšŒìƒì„ ê±´ë„ˆëœë‹ˆë‹¤")
            return []
        
        try:
            logger.info(f"ğŸ” í•™ìŠµ ë°ì´í„° íšŒìƒ ì‹œì‘ - ì¿¼ë¦¬: '{query}', ì‚¬ìš©ì: {user_id}")
            
            all_results = []
            
            # 1. ê°•í™”ëœ í•™ìŠµ ì‹œìŠ¤í…œ ë°ì´í„° ê²€ìƒ‰
            enhanced_results = await self._search_enhanced_learning(query, category, filename, limit)
            all_results.extend(enhanced_results)
            
            # 2. ë¬¸ì„œ ì²­í¬ ë°ì´í„° ê²€ìƒ‰
            chunk_results = await self._search_document_chunks(query, category, filename, limit)
            all_results.extend(chunk_results)
            
            # 3. ê¸°íƒ€ í•™ìŠµ ê´€ë ¨ ë°ì´í„° ê²€ìƒ‰
            other_results = await self._search_other_learning_data(query, memory_type, limit)
            all_results.extend(other_results)
            
            # 4. ì¤‘ë³µ ì œê±° ë° ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
            unique_results = self._remove_duplicates(all_results)
            scored_results = self._calculate_relevance_scores(unique_results, query)
            
            # 5. ê²°ê³¼ ì •ë ¬ ë° ì œí•œ
            final_results = sorted(scored_results, key=lambda x: x.get('relevance_score', 0), reverse=True)[:limit]
            
            # 6. ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = self._format_results(final_results)
            
            logger.info(f"âœ… í•™ìŠµ ë°ì´í„° íšŒìƒ ì™„ë£Œ - ê²°ê³¼: {len(formatted_results)}ê°œ")
            return formatted_results
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ ë°ì´í„° íšŒìƒ ì˜¤ë¥˜: {e}")
            import traceback
            logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return []
    
    async def _search_enhanced_learning(self, query: str, category: str, filename: str, limit: int) -> List[Dict]:
        """ê°•í™”ëœ í•™ìŠµ ì‹œìŠ¤í…œ ë°ì´í„° ê²€ìƒ‰"""
        try:
            search_query = {"memory_type": "enhanced_learning"}
            
            # ì¹´í…Œê³ ë¦¬ í•„í„°
            if category:
                search_query["category"] = {"$regex": category, "$options": "i"}
            
            # íŒŒì¼ëª… í•„í„°
            if filename:
                search_query["source_file"] = {"$regex": filename, "$options": "i"}
            
            # í…ìŠ¤íŠ¸ ê²€ìƒ‰
            if query:
                text_conditions = [
                    {"response": {"$regex": query, "$options": "i"}},
                    {"message": {"$regex": query, "$options": "i"}},
                    {"tags": {"$in": [query]}},
                    {"category": {"$regex": query, "$options": "i"}},
                    {"source_file": {"$regex": query, "$options": "i"}}
                ]
                search_query = {"$and": [search_query, {"$or": text_conditions}]}
            
            cursor = self.db.memories.find(search_query).sort("timestamp", -1).limit(limit * 2)
            results = list(cursor)
            
            logger.info(f"ğŸ“š enhanced_learning ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ enhanced_learning ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def _search_document_chunks(self, query: str, category: str, filename: str, limit: int) -> List[Dict]:
        """ë¬¸ì„œ ì²­í¬ ë°ì´í„° ê²€ìƒ‰"""
        try:
            search_query = {"memory_type": "document_chunk"}
            
            # ê´€ë¦¬ì ê³µìœ  ë°ì´í„° ìš°ì„  ê²€ìƒ‰
            admin_query = search_query.copy()
            admin_query["metadata.admin_shared"] = True
            admin_query["source"] = "file_learning"
            
            # ì¹´í…Œê³ ë¦¬ í•„í„°
            if category:
                admin_query["metadata.category"] = {"$regex": category, "$options": "i"}
            
            # íŒŒì¼ëª… í•„í„°
            if filename:
                admin_query["filename"] = {"$regex": filename, "$options": "i"}
            
            # í…ìŠ¤íŠ¸ ê²€ìƒ‰
            if query:
                text_conditions = [
                    {"content": {"$regex": query, "$options": "i"}},
                    {"keywords": {"$in": [query]}},
                    {"topic": {"$regex": query, "$options": "i"}},
                    {"filename": {"$regex": query, "$options": "i"}},
                    {"metadata.filename": {"$regex": query, "$options": "i"}}
                ]
                admin_query = {"$and": [admin_query, {"$or": text_conditions}]}
            
            # ê´€ë¦¬ì ê³µìœ  ë°ì´í„° ê²€ìƒ‰
            cursor = self.db.memories.find(admin_query).sort("timestamp", -1).limit(limit)
            admin_results = list(cursor)
            
            results = admin_results
            
            # ê²°ê³¼ê°€ ë¶€ì¡±í•˜ë©´ ì¼ë°˜ document_chunkë„ ê²€ìƒ‰
            if len(results) < limit:
                remaining_limit = limit - len(results)
                fallback_query = {"memory_type": "document_chunk", "source": "file_learning"}
                
                if query:
                    fallback_query = {"$and": [fallback_query, {"$or": text_conditions}]}
                
                # ì´ë¯¸ ì°¾ì€ ê²°ê³¼ ì œì™¸
                existing_ids = [result["_id"] for result in results]
                if existing_ids:
                    fallback_query["_id"] = {"$nin": existing_ids}
                
                cursor = self.db.memories.find(fallback_query).sort("timestamp", -1).limit(remaining_limit)
                fallback_results = list(cursor)
                results.extend(fallback_results)
            
            logger.info(f"ğŸ“„ document_chunk ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ document_chunk ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    async def _search_other_learning_data(self, query: str, memory_type: str, limit: int) -> List[Dict]:
        """ê¸°íƒ€ í•™ìŠµ ê´€ë ¨ ë°ì´í„° ê²€ìƒ‰"""
        try:
            search_query = {}
            
            # íŠ¹ì • ë©”ëª¨ë¦¬ íƒ€ì…ì´ ì§€ì •ëœ ê²½ìš°
            if memory_type:
                search_query["memory_type"] = memory_type
            else:
                # í•™ìŠµ ê´€ë ¨ ë©”ëª¨ë¦¬ íƒ€ì…ë“¤
                learning_types = ["file_learning", "document_learning", "knowledge_base", "training_data"]
                search_query["memory_type"] = {"$in": learning_types}
            
            # í…ìŠ¤íŠ¸ ê²€ìƒ‰
            if query:
                text_conditions = [
                    {"content": {"$regex": query, "$options": "i"}},
                    {"response": {"$regex": query, "$options": "i"}},
                    {"message": {"$regex": query, "$options": "i"}},
                    {"keywords": {"$in": [query]}},
                    {"topic": {"$regex": query, "$options": "i"}}
                ]
                search_query = {"$and": [search_query, {"$or": text_conditions}]}
            
            cursor = self.db.memories.find(search_query).sort("timestamp", -1).limit(limit)
            results = list(cursor)
            
            logger.info(f"ğŸ“‹ ê¸°íƒ€ í•™ìŠµ ë°ì´í„° ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ê¸°íƒ€ í•™ìŠµ ë°ì´í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _remove_duplicates(self, results: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ê²°ê³¼ ì œê±°"""
        seen_ids = set()
        unique_results = []
        
        for result in results:
            result_id = str(result.get("_id"))
            if result_id not in seen_ids:
                seen_ids.add(result_id)
                unique_results.append(result)
        
        return unique_results
    
    def _calculate_relevance_scores(self, results: List[Dict], query: str) -> List[Dict]:
        """ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        if not query:
            for result in results:
                result["relevance_score"] = 1.0
            return results
        
        query_lower = query.lower()
        query_words = query_lower.split()
        
        for result in results:
            score = 0
            
            # ë‚´ìš©ì—ì„œ ê²€ìƒ‰
            content = result.get("content", result.get("response", "")).lower()
            
            # ì •í™•í•œ ë§¤ì¹˜
            if query_lower in content:
                score += 5
            
            # í‚¤ì›Œë“œ ë§¤ì¹˜
            keywords = result.get("keywords", [])
            if any(query_lower in str(kw).lower() for kw in keywords):
                score += 3
            
            # ì£¼ì œ/ì¹´í…Œê³ ë¦¬ ë§¤ì¹˜
            topic = result.get("topic", result.get("category", "")).lower()
            if query_lower in topic:
                score += 3
            
            # íŒŒì¼ëª… ë§¤ì¹˜
            filename = result.get("filename", result.get("source_file", "")).lower()
            if query_lower in filename:
                score += 2
            
            # ë‹¨ì–´ë³„ ë¶€ë¶„ ë§¤ì¹˜
            for word in query_words:
                if len(word) > 2:  # 2ê¸€ì ì´ìƒë§Œ
                    if word in content:
                        score += 1
                    if word in topic:
                        score += 0.5
                    if word in filename:
                        score += 0.5
            
            # ë©”ëª¨ë¦¬ íƒ€ì…ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
            memory_type = result.get("memory_type", "")
            if memory_type == "enhanced_learning":
                score += 1
            elif memory_type == "document_chunk":
                score += 0.8
            
            # admin_shared ë°ì´í„°ì— ê°€ì¤‘ì¹˜
            if result.get("metadata", {}).get("admin_shared"):
                score += 1
            
            result["relevance_score"] = score
        
        return results
    
    def _format_results(self, results: List[Dict]) -> List[Dict]:
        """ê²°ê³¼ í¬ë§·íŒ…"""
        formatted_results = []
        
        for result in results:
            formatted_result = {
                "_id": str(result.get("_id")),
                "content": result.get("content", result.get("response", "")),
                "memory_type": result.get("memory_type", ""),
                "relevance_score": result.get("relevance_score", 0),
                "timestamp": result.get("timestamp")
            }
            
            # íŒŒì¼ëª…
            if "filename" in result:
                formatted_result["filename"] = result["filename"]
            elif "source_file" in result:
                formatted_result["filename"] = result["source_file"]
            
            # ì¹´í…Œê³ ë¦¬
            if "category" in result:
                formatted_result["category"] = result["category"]
            elif result.get("metadata", {}).get("category"):
                formatted_result["category"] = result["metadata"]["category"]
            
            # í‚¤ì›Œë“œ/íƒœê·¸
            if "keywords" in result:
                formatted_result["keywords"] = result["keywords"]
            elif "tags" in result:
                formatted_result["keywords"] = result["tags"]
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            if "metadata" in result:
                formatted_result["metadata"] = result["metadata"]
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ í¬ë§·íŒ…
            if formatted_result["timestamp"] and hasattr(formatted_result["timestamp"], "isoformat"):
                formatted_result["timestamp"] = formatted_result["timestamp"].isoformat()
            
            formatted_results.append(formatted_result)
        
        return formatted_results
    
    async def get_learning_statistics(self) -> Dict[str, Any]:
        """í•™ìŠµ ë°ì´í„° í†µê³„"""
        if not self.is_connected():
            return {"error": "MongoDB ì—°ê²° ì—†ìŒ"}
        
        try:
            stats = {}
            
            # ì „ì²´ ë©”ëª¨ë¦¬ ìˆ˜
            stats["total_memories"] = self.db.memories.count_documents({})
            
            # ê°•í™”ëœ í•™ìŠµ ë©”ëª¨ë¦¬
            stats["enhanced_learning"] = self.db.memories.count_documents({"memory_type": "enhanced_learning"})
            
            # ë¬¸ì„œ ì²­í¬
            stats["document_chunks"] = self.db.memories.count_documents({"memory_type": "document_chunk"})
            
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            pipeline = [
                {"$match": {"memory_type": {"$in": ["enhanced_learning", "document_chunk"]}}},
                {"$group": {
                    "_id": "$category",
                    "count": {"$sum": 1}
                }},
                {"$sort": {"count": -1}}
            ]
            category_stats = list(self.db.memories.aggregate(pipeline))
            stats["categories"] = category_stats
            
            # íŒŒì¼ë³„ í†µê³„
            pipeline = [
                {"$match": {"memory_type": {"$in": ["enhanced_learning", "document_chunk"]}}},
                {"$group": {
                    "_id": {"$ifNull": ["$filename", "$source_file"]},
                    "count": {"$sum": 1},
                    "latest": {"$max": "$timestamp"}
                }},
                {"$sort": {"latest": -1}}
            ]
            file_stats = list(self.db.memories.aggregate(pipeline))
            stats["files"] = file_stats[:10]  # ìµœê·¼ 10ê°œë§Œ
            
            stats["timestamp"] = datetime.now().isoformat()
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
enhanced_recall_system = None

def get_enhanced_recall_system(mongo_client=None):
    """í–¥ìƒëœ íšŒìƒ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global enhanced_recall_system
    if enhanced_recall_system is None:
        enhanced_recall_system = EnhancedRecallSystem(mongo_client)
    return enhanced_recall_system