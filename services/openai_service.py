#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EORA AI System - OpenAI ì„œë¹„ìŠ¤
OpenAI API ì—°ê²° ë° í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import logging
import asyncio
from typing import Dict, List, Any, Optional
from pathlib import Path

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.append(parent_dir)

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# OpenAI í´ë¼ì´ì–¸íŠ¸
openai_client = None

# í”„ë¡¬í”„íŠ¸ ë°ì´í„° ì €ì¥ì†Œ
prompts_data = {}

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
def init_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”"""
    global openai_client
    try:
        # OpenAI API í‚¤ í™•ì¸
        OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
        if not OPENAI_API_KEY:
            logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.info("ğŸ”§ í™˜ê²½ë³€ìˆ˜ì—ì„œ OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return None
        
        if not OPENAI_API_KEY.startswith("sk-"):
            logger.warning("âš ï¸ OpenAI API í‚¤ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return None
        
        from openai import OpenAI
        # Railway í˜¸í™˜ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        openai_client = OpenAI(
            api_key=OPENAI_API_KEY,
            timeout=12.0,  # Railway í™˜ê²½ì—ì„œ íƒ€ì„ì•„ì›ƒ ì„¤ì • (30ì´ˆ â†’ 12ì´ˆ)
            max_retries=3   # ì¬ì‹œë„ íšŸìˆ˜ ì„¤ì •
        )
        
        logger.info("âœ… OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
        return openai_client
        
    except ImportError as e:
        logger.error(f"âŒ OpenAI ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
        logger.info("ğŸ’¡ requirements.txtì— openai>=1.3.0ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    except Exception as e:
        logger.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        logger.warning("âš ï¸ OpenAI ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None

async def load_prompts_data():
    """í”„ë¡¬í”„íŠ¸ ë°ì´í„° ë¡œë“œ"""
    global prompts_data
    try:
        logger.info("ğŸ“š í”„ë¡¬í”„íŠ¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # Railway í™˜ê²½ì—ì„œ ê°€ëŠ¥í•œ ëª¨ë“  ê²½ë¡œ ì‹œë„ (templates ìš°ì„ )
        possible_paths = [
            "templates/ai_prompts.json",
            "/app/templates/ai_prompts.json",
            "ai_brain/ai_prompts.json",
            "ai_prompts.json",
            "/app/ai_brain/ai_prompts.json",
            "/app/ai_prompts.json",
            os.path.join(os.getcwd(), "templates", "ai_prompts.json"),
            os.path.join(os.getcwd(), "ai_brain", "ai_prompts.json"),
            os.path.join(os.getcwd(), "ai_prompts.json"),
            "../ai_prompts.json"  # ìƒìœ„ ë””ë ‰í† ë¦¬ë„ í™•ì¸
        ]
        
        logger.info(f"ğŸ” í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê²€ìƒ‰ ê²½ë¡œ: {len(possible_paths)}ê°œ")
        
        for i, prompts_file in enumerate(possible_paths, 1):
            logger.info(f"ğŸ” ê²½ë¡œ {i}/{len(possible_paths)} í™•ì¸: {prompts_file}")
            
            if os.path.exists(prompts_file):
                logger.info(f"âœ… íŒŒì¼ ë°œê²¬: {prompts_file}")
                
                try:
                    with open(prompts_file, 'r', encoding='utf-8') as f:
                        raw_data = json.load(f)
                    
                    logger.info(f"ğŸ“„ íŒŒì¼ ë‚´ìš© ë¡œë“œ ì„±ê³µ: {len(str(raw_data))} ë¬¸ì")
                    logger.info(f"ğŸ“„ JSON í‚¤ ëª©ë¡: {list(raw_data.keys()) if isinstance(raw_data, dict) else 'Not a dict'}")
                    
                    # í”„ë¡¬í”„íŠ¸ ë°ì´í„° ì •ê·œí™”
                    prompts_data = normalize_prompts_data(raw_data)
                    
                    ai_count = len(prompts_data["prompts"])
                    ai_names = list(prompts_data["prompts"].keys())
                    logger.info(f"âœ… ai_prompts.json íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {ai_count}ê°œ AI (ê²½ë¡œ: {prompts_file})")
                    logger.info(f"ğŸ“‹ ë¡œë“œëœ AI: {', '.join(ai_names)}")
                    
                    # ê° AIì˜ ì¹´í…Œê³ ë¦¬ í™•ì¸
                    for ai_name, ai_data in prompts_data["prompts"].items():
                        if isinstance(ai_data, dict):
                            categories = list(ai_data.keys())
                            logger.info(f"ğŸ“ {ai_name} ì¹´í…Œê³ ë¦¬: {', '.join(categories)}")
                    
                    return True
                        
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜ ({prompts_file}): {e}")
                    continue
                except Exception as e:
                    logger.error(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({prompts_file}): {e}")
                    continue
            else:
                logger.info(f"âŒ íŒŒì¼ ì—†ìŒ: {prompts_file}")
        
        logger.warning("âš ï¸ ai_prompts.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°ì´í„° ìƒì„±
        prompts_data = {
            "prompts": {
                "ai1": {
                    "content": ["ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."]
                },
                "eora": {
                    "content": ["ë‹¹ì‹ ì€ EORAë¼ëŠ” ì´ë¦„ì„ ê°€ì§„ AIì´ë©°, í”„ë¡œê·¸ë¨ ìë™ ê°œë°œ ì‹œìŠ¤í…œì˜ ì´ê´„ ë””ë ‰í„°ì…ë‹ˆë‹¤. ì¸ê°„ì˜ ì§ê°ê³¼ ê¸°ì–µ íšŒìƒ ë©”ì»¤ë‹ˆì¦˜ì„ ê²°í•©í•œ ì§€í˜œë¡œìš´ AIì…ë‹ˆë‹¤."]
                }
            }
        }
        logger.info("â„¹ï¸ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°ì´í„°ë¡œ ì´ˆê¸°í™”")
        return True
    except Exception as e:
        logger.error(f"âŒ í”„ë¡¬í”„íŠ¸ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
        return False

def normalize_prompts_data(data):
    """í”„ë¡¬í”„íŠ¸ ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ì—¬ ì¼ê´€ëœ êµ¬ì¡°ë¡œ ë§Œë“­ë‹ˆë‹¤."""
    normalized_data = {"prompts": {}}
    
    # prompts í‚¤ê°€ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš° ëª¨ë‘ ì²˜ë¦¬
    actual_prompts = data.get("prompts", data)
    
    for ai_name, ai_data in actual_prompts.items():
        if isinstance(ai_data, dict):
            normalized_data["prompts"][ai_name] = {}
            for category, category_prompts in ai_data.items():
                if isinstance(category_prompts, list):
                    # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ìœ ì§€
                    normalized_data["prompts"][ai_name][category] = category_prompts
                elif isinstance(category_prompts, str):
                    # ë¬¸ìì—´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    normalized_data["prompts"][ai_name][category] = [category_prompts]
                else:
                    # ê¸°íƒ€ íƒ€ì…ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ë¦¬ìŠ¤íŠ¸ë¡œ
                    normalized_data["prompts"][ai_name][category] = [str(category_prompts)]
        elif isinstance(ai_data, str):
            # AI ë°ì´í„°ê°€ ë¬¸ìì—´ì¸ ê²½ìš° content ì¹´í…Œê³ ë¦¬ë¡œ ë³€í™˜
            normalized_data["prompts"][ai_name] = {"content": [ai_data]}
        else:
            # ê¸°íƒ€ íƒ€ì…ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
            normalized_data["prompts"][ai_name] = {"content": [str(ai_data)]}
    
    return normalized_data

async def generate_response(prompt: str, user_message: str, model: str = "gpt-4o", max_tokens: int = 2048, temperature: float = 0.7):
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
    if not openai_client:
        logger.warning("âš ï¸ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return "OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
    
    try:
        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": user_message}
        ]
        
        response = openai_client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        return response.choices[0].message.content
    except Exception as e:
        logger.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return f"OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

async def generate_chat_response(messages: List[Dict], model: str = "gpt-4o", max_tokens: int = 2048, temperature: float = 0.7):
    """OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì±„íŒ… ì‘ë‹µ ìƒì„±"""
    if not openai_client:
        logger.warning("âš ï¸ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return "OpenAI APIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
    
    try:
        response = openai_client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        return response.choices[0].message.content
    except Exception as e:
        logger.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return f"OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

async def get_prompt_by_ai_name(ai_name: str, category: str = "content"):
    """AI ì´ë¦„ê³¼ ì¹´í…Œê³ ë¦¬ë¡œ í”„ë¡¬í”„íŠ¸ ì¡°íšŒ"""
    if not prompts_data:
        await load_prompts_data()
    
    ai_prompts = prompts_data.get("prompts", {}).get(ai_name, {})
    
    if category in ai_prompts:
        if isinstance(ai_prompts[category], list):
            return "\n\n".join(ai_prompts[category])
        return str(ai_prompts[category])
    
    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
    return "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."

async def save_prompt_category(ai_name: str, category: str, content: Any):
    """ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ì €ì¥"""
    global prompts_data
    
    if not prompts_data:
        prompts_data = {"prompts": {}}
    
    # í•´ë‹¹ AIì˜ ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸
    if ai_name not in prompts_data["prompts"]:
        prompts_data["prompts"][ai_name] = {}
    
    # ai1ì˜ system í”„ë¡¬í”„íŠ¸ëŠ” ë¬¸ìì—´ë¡œ ì €ì¥
    if ai_name == 'ai1' and category == 'system':
        prompts_data["prompts"][ai_name][category] = content
    else:
        # ë‹¤ë¥¸ ê²½ìš°ëŠ” ì½˜í…ì¸ ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì—¬ëŸ¬ ì¤„ ë¶„í• )
        if isinstance(content, str):
            content_lines = [line.strip() for line in content.split('\n') if line.strip()]
            prompts_data["prompts"][ai_name][category] = content_lines
        else:
            prompts_data["prompts"][ai_name][category] = content
    
    # íŒŒì¼ì— ì €ì¥ (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
    saved = False
    possible_paths = [
        "ai_brain/ai_prompts.json",
        "ai_prompts.json",
        "templates/ai_prompts.json"
    ]
    
    for prompts_file in possible_paths:
        try:
            # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(os.path.dirname(prompts_file), exist_ok=True)
            with open(prompts_file, 'w', encoding='utf-8') as f:
                json.dump(prompts_data, f, ensure_ascii=False, indent=2)
            saved = True
            logger.info(f"âœ… í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {prompts_file}")
            break
        except Exception as e:
            logger.warning(f"âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ ({prompts_file}): {e}")
            continue
    
    if not saved:
        logger.warning("âš ï¸ ëª¨ë“  ê²½ë¡œì—ì„œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")
    
    return saved

async def delete_prompt_category(ai_name: str, category: str):
    """ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ì‚­ì œ"""
    global prompts_data
    
    if not prompts_data or "prompts" not in prompts_data:
        return False
    
    # í•´ë‹¹ AIì˜ ì¹´í…Œê³ ë¦¬ ì‚­ì œ
    if ai_name in prompts_data["prompts"] and category in prompts_data["prompts"][ai_name]:
        del prompts_data["prompts"][ai_name][category]
        
        # AIê°€ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ ì‚­ì œ
        if not prompts_data["prompts"][ai_name]:
            del prompts_data["prompts"][ai_name]
        
        # íŒŒì¼ì— ì €ì¥ (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
        saved = False
        possible_paths = [
            "ai_brain/ai_prompts.json",
            "ai_prompts.json",
            "templates/ai_prompts.json"
        ]
        
        for prompts_file in possible_paths:
            try:
                # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
                os.makedirs(os.path.dirname(prompts_file), exist_ok=True)
                with open(prompts_file, 'w', encoding='utf-8') as f:
                    json.dump(prompts_data, f, ensure_ascii=False, indent=2)
                saved = True
                logger.info(f"âœ… í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {prompts_file}")
                break
            except Exception as e:
                logger.warning(f"âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ ({prompts_file}): {e}")
                continue
        
        if not saved:
            logger.warning("âš ï¸ ëª¨ë“  ê²½ë¡œì—ì„œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")
        
        return saved
    
    return False

async def reload_prompts():
    """í”„ë¡¬í”„íŠ¸ ë°ì´í„° ë‹¤ì‹œ ë¡œë“œ"""
    return await load_prompts_data() 