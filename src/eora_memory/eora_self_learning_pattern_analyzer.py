"""
EORA ì‚¬ìš©ì ê°ì •/ì‹ ë… íŒ¨í„´ ë¶„ì„ê¸°
- MongoDB memory_atoms ê¸°ë°˜
- ì‚¬ìš©ìë³„ ê°ì • ë°˜ë³µ, íšŒë³µ ì†ë„, ì‹ ë… ë³€í™” ë¶„ì„
"""

import sys, os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "aura_system")))
from pymongo import MongoClient
from datetime import datetime, timedelta
import pandas as pd
from collections import defaultdict

mongo_client = MongoClient("mongodb://localhost:27017")
db = mongo_client["aura_memory"]
collection = db["memory_atoms"]

def analyze_user_patterns(user_id="default_user", days=30):
    cutoff = datetime.utcnow() - timedelta(days=days)
    memories = list(collection.find({"timestamp": {"$gte": cutoff.isoformat()}}))

    emotion_counts = defaultdict(int)
    belief_changes = 0
    recovery_delays = []

    for mem in memories:
        if mem.get("emotion_label"):
            emotion_counts[mem["emotion_label"]] += 1

        if mem.get("belief_detected") and mem.get("belief_reframed"):
            belief_changes += 1

        if mem.get("emotion_score", 0) <= 0.6 and mem.get("importance", 0) >= 8000:
            delay_days = (datetime.utcnow() - datetime.fromisoformat(mem["timestamp"])).days
            recovery_delays.append(delay_days)

    avg_delay = round(sum(recovery_delays) / len(recovery_delays), 2) if recovery_delays else 0

    print(f"ğŸ“Š ì‚¬ìš©ì {user_id} ë¶„ì„ ê²°ê³¼:")
    print(f"  - ê°ì • ì¶œí˜„: {dict(emotion_counts)}")
    print(f"  - ì‹ ë… ë¦¬í”„ë ˆì„ ë°œìƒ: {belief_changes}íšŒ")
    print(f"  - í‰ê·  íšŒë³µ ì§€ì—°ì¼ìˆ˜: {avg_delay}ì¼")

    return {
        "user_id": user_id,
        "emotion_pattern": dict(emotion_counts),
        "belief_change_count": belief_changes,
        "avg_recovery_delay": avg_delay
    }

if __name__ == "__main__":
    analyze_user_patterns()