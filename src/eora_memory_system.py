"""
EORA ì™„ì „ í†µí•© ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
- ì €ì¥: ê°ì •, ì‹ ë…, ë§¥ë½, ì—°ê²°ì„ í¬í•¨í•œ ë‹¤ì°¨ì› ë©”ëª¨ë¦¬ ì €ì¥
- íšŒìƒ: ê°ì • ê¸°ë°˜, ë§¥ë½ ê¸°ë°˜, ì—°ê²° ê¸°ë°˜ ë‹¤ì¤‘ íšŒìƒ ì „ëµ
"""

import json
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from pymongo import MongoClient
from bson import ObjectId
import re
import hashlib

logger = logging.getLogger(__name__)

class EORAMemorySystem:
    """ì™„ì „ í†µí•©ëœ EORA ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, mongo_uri=None):
        # MongoDB ì—°ê²° ì„¤ì • - database.pyì™€ ì—°ê²° ì •ë³´ ê³µìœ 
        if mongo_uri is None:
            import os
            
            # 1ìˆœìœ„: database.pyì—ì„œ ì´ë¯¸ ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ ë˜ëŠ” URL ì‚¬ìš©
            try:
                import sys
                sys.path.append('.')
                from database import get_cached_mongodb_connection, get_mongodb_url, MONGODB_URL
                
                # ì´ë¯¸ ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
                cached_client = get_cached_mongodb_connection()
                if cached_client:
                    try:
                        cached_client.admin.command('ping')
                        logger.info("âœ… database.pyì˜ ê¸°ì¡´ MongoDB ì—°ê²° ì¬ì‚¬ìš©")
                        self.client = cached_client
                        self.db = self.client["eora_memory"]
                        self._setup_collections()
                        self._create_indexes()
                        
                        # ë©”ëª¨ë¦¬ ì„¤ì • ë° memory_manager ì´ˆê¸°í™”
                        self.max_memories_per_user = 1000
                        self.recall_limit = 10
                        self.emotion_threshold = 0.3
                        self.connection_threshold = 0.5
                        self.memory_manager = None
                        self._initialize_memory_manager()
                        
                        return  # ì„±ê³µì ìœ¼ë¡œ ì—°ê²° ì¬ì‚¬ìš©
                    except:
                        logger.warning("âš ï¸ ê¸°ì¡´ ì—°ê²°ì´ ëŠì–´ì ¸ ìˆìŒ, ìƒˆë¡œ ì—°ê²° ì‹œë„")
                
                # ê¸°ì¡´ ì—°ê²°ì´ ì—†ìœ¼ë©´ URL ê°€ì ¸ì˜¤ê¸°
                mongo_uri = get_mongodb_url()
                if mongo_uri and mongo_uri != "mongodb://localhost:27017":
                    logger.info(f"âœ… database.py get_mongodb_url()ì—ì„œ URL ê°€ì ¸ì˜´: {mongo_uri[:50]}...")
                elif MONGODB_URL and MONGODB_URL != "mongodb://localhost:27017":
                    mongo_uri = MONGODB_URL
                    logger.info(f"âœ… database.py MONGODB_URLì—ì„œ URL ê°€ì ¸ì˜´: {mongo_uri[:50]}...")
                else:
                    mongo_uri = None
                    
            except (ImportError, Exception) as e:
                logger.warning(f"âš ï¸ database.py ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
                mongo_uri = None
            
            # 2ìˆœìœ„: ì§ì ‘ í™˜ê²½ë³€ìˆ˜ì—ì„œ Railway MongoDB URL ì°¾ê¸°
            if not mongo_uri:
                is_railway = any([
                    os.getenv("RAILWAY_ENVIRONMENT"),
                    os.getenv("RAILWAY_PROJECT_ID"),
                    os.getenv("RAILWAY_SERVICE_ID")
                ])
                
                if is_railway:
                    # Railway í™˜ê²½ë³€ìˆ˜ í™•ì¸ (í¬ê´„ì )
                    railway_env_keys = [
                        "MONGODB_URL", "MONGO_URL", "MONGO_PUBLIC_URL", "MONGO_PRIVATE_URL",
                        "DATABASE_URL", "DB_URL", "MONGODB_URI", "MONGO_URI"
                    ]
                    
                    logger.info(f"ğŸ” Railway í™˜ê²½ì—ì„œ MongoDB URL ê²€ìƒ‰ ì¤‘...")
                    
                    for key in railway_env_keys:
                        value = os.getenv(key)
                        if value and value.startswith("mongodb://"):
                            mongo_uri = value.strip()
                            logger.info(f"âœ… í™˜ê²½ë³€ìˆ˜ {key}ì—ì„œ MongoDB URL ë°œê²¬: {mongo_uri[:50]}...")
                            break
                    
                    # ê°œë³„ ë³€ìˆ˜ë¡œ êµ¬ì„± ì‹œë„
                    if not mongo_uri and all([os.getenv('MONGOUSER'), os.getenv('MONGOPASSWORD'), 
                                            os.getenv('MONGOHOST'), os.getenv('MONGOPORT')]):
                        mongo_uri = f"mongodb://{os.getenv('MONGOUSER')}:{os.getenv('MONGOPASSWORD')}@{os.getenv('MONGOHOST')}:{os.getenv('MONGOPORT')}"
                        logger.info(f"âœ… ê°œë³„ í™˜ê²½ë³€ìˆ˜ë¡œ MongoDB URL êµ¬ì„±: {mongo_uri[:50]}...")
                
                # ë¡œì»¬ í™˜ê²½ì´ê±°ë‚˜ Railwayì—ì„œ URLì„ ëª» ì°¾ì€ ê²½ìš°
                if not mongo_uri:
                    mongo_uri = os.getenv("MONGODB_URI", "mongodb://localhost:27017")
                    if mongo_uri == "mongodb://localhost:27017":
                        logger.info(f"âœ… ê¸°ë³¸ localhost ì‚¬ìš©: {mongo_uri}")
                    else:
                        logger.info(f"âœ… MONGODB_URI í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©: {mongo_uri[:50]}...")
        
        # ìµœì¢… fallback
        if not mongo_uri:
            mongo_uri = "mongodb://localhost:27017"
            logger.warning(f"âš ï¸ ìµœì¢… fallback - localhost ì‚¬ìš©: {mongo_uri}")
        
        self.mongo_uri = mongo_uri
        self.client = None
        self.db = None
        self.memories = None
        
        # ì´ë¯¸ database.py ì—°ê²°ì„ ì¬ì‚¬ìš©í•œ ê²½ìš°ê°€ ì•„ë‹ˆë¼ë©´ ìƒˆë¡œ ì—°ê²°
        if self.client is None:
            
            # MongoDB ì—°ê²° ì‹œë„ (Railway í™˜ê²½ì— ë§ëŠ” ì„¤ì •)
            try:
                # Railway í™˜ê²½ ê°ì§€
                import os
                is_railway = any([
                    os.getenv("RAILWAY_ENVIRONMENT"),
                    os.getenv("RAILWAY_PROJECT_ID"),
                    os.getenv("RAILWAY_SERVICE_ID")
                ])
                
                # Railway í™˜ê²½ì— ë§ëŠ” ì—°ê²° ì˜µì…˜ ì„¤ì •
                connect_options = {
                    "serverSelectionTimeoutMS": 10000,  # Railwayì—ì„œëŠ” ë” ê¸´ íƒ€ì„ì•„ì›ƒ
                    "connectTimeoutMS": 10000,
                    "socketTimeoutMS": 20000,
                }
                
                if is_railway:
                    connect_options.update({
                        "retryWrites": True,
                        "w": "majority",
                        "readPreference": "primary",
                        "maxPoolSize": 10,
                        "minPoolSize": 1
                    })
                
                self.client = MongoClient(mongo_uri, **connect_options)
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸
                self.client.admin.command('ping')
                self.db = self.client["eora_memory"]
                
                # ì»¬ë ‰ì…˜ ì„¤ì •
                self._setup_collections()
                
                logger.info(f"âœ… MongoDB ì—°ê²° ì„±ê³µ: {mongo_uri}")
                
                # ì¸ë±ìŠ¤ ìƒì„±
                self._create_indexes()
                
            except Exception as e:
                logger.error(f"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {str(e)}")
                logger.error(f"   URI: {mongo_uri}")
                # ì—°ê²° ì‹¤íŒ¨ ì‹œì—ë„ ê°ì²´ëŠ” ìƒì„±í•˜ë˜, ì»¬ë ‰ì…˜ë“¤ì„ Noneìœ¼ë¡œ ì„¤ì •
                self.client = None
                self.db = None
                self.memories = None
                self.emotion_memories = None
                self.belief_memories = None
                self.context_memories = None
                self.connection_index = None
            
        # ë©”ëª¨ë¦¬ ì„¤ì •
        self.max_memories_per_user = 1000
        self.recall_limit = 10
        self.emotion_threshold = 0.3
        self.connection_threshold = 0.5
        
        # memory_manager ì´ˆê¸°í™” (RecallEngineê³¼ í˜¸í™˜ì„±ì„ ìœ„í•´)
        self.memory_manager = None
        self._initialize_memory_manager()
    
    def _initialize_memory_manager(self):
        """memory_manager ì´ˆê¸°í™” (RecallEngine í˜¸í™˜ì„±) - Railway í™˜ê²½ ëŒ€ì‘"""
        try:
            # Railway í™˜ê²½ í™•ì¸
            import os
            is_railway = any([
                os.getenv("RAILWAY_ENVIRONMENT"),
                os.getenv("RAILWAY_PROJECT_ID"),
                os.getenv("RAILWAY_SERVICE_ID")
            ])
            
            if is_railway:
                logger.info("ğŸš‚ Railway í™˜ê²½ì—ì„œ memory_manager ì´ˆê¸°í™” ì‹œë„...")
                
                # Railwayì—ì„œëŠ” ê²½ëŸ‰í™”ëœ memory_manager ìƒì„±
                self.memory_manager = self._create_lightweight_memory_manager()
                
                if self.memory_manager:
                    logger.info("âœ… Railwayìš© ê²½ëŸ‰ memory_manager ìƒì„± ì™„ë£Œ")
                else:
                    logger.warning("âš ï¸ Railwayì—ì„œ memory_manager ìƒì„± ì‹¤íŒ¨ - ê¸°ë³¸ íšŒìƒ ì‚¬ìš©")
            else:
                # ë¡œì»¬ í™˜ê²½ì—ì„œëŠ” OpenAI API ì˜¤ë¥˜ ì‹œ ì¦‰ì‹œ ê²½ëŸ‰ ë²„ì „ ì‚¬ìš©
                logger.info("ğŸ’» ë¡œì»¬ í™˜ê²½ì—ì„œ memory_manager ì´ˆê¸°í™” ì‹œë„...")
                
                # í•­ìƒ ê²½ëŸ‰ ë²„ì „ ì‚¬ìš© (ë¬´í•œë£¨í”„ ë°©ì§€)
                logger.info("âš¡ ë¹ ë¥¸ ì´ˆê¸°í™”ë¥¼ ìœ„í•´ ê²½ëŸ‰ memory_manager ì‚¬ìš©")
                self.memory_manager = self._create_lightweight_memory_manager()
                
        except Exception as e:
            logger.warning(f"âš ï¸ memory_manager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ìµœì¢… fallbackìœ¼ë¡œ ê²½ëŸ‰ ë²„ì „ ìƒì„±
            self.memory_manager = self._create_lightweight_memory_manager()
    
    def _create_lightweight_memory_manager(self):
        """Railway í™˜ê²½ìš© ê²½ëŸ‰ memory_manager ìƒì„±"""
        try:
            # self ì°¸ì¡°ë¥¼ ìº¡ì²˜í•˜ì—¬ MongoDBì— ì ‘ê·¼
            eora_system = self
            
            class LightweightMemoryManager:
                def __init__(self):
                    self.is_initialized = True
                    self.memories = {}
                    
                async def store_memory_async(self, content, metadata=None):
                    """ë©”ëª¨ë¦¬ ì €ì¥ (ê°„ë‹¨ ë²„ì „)"""
                    memory_id = f"mem_{len(self.memories)}"
                    self.memories[memory_id] = {
                        "content": content,
                        "metadata": metadata or {},
                        "timestamp": datetime.now().isoformat()
                    }
                    return {"success": True, "memory_id": memory_id}
                
                async def recall_memories_async(self, query, limit=5):
                    """ë©”ëª¨ë¦¬ íšŒìƒ (MongoDB ì—°ë™ ë²„ì „)"""
                    results = []
                    query_lower = query.lower()
                    
                    try:
                        # MongoDBì—ì„œ ì‹¤ì œ ë°ì´í„° ê²€ìƒ‰
                        if eora_system.is_connected():
                            # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¡°ê±´
                            search_conditions = []
                            
                            # ì „ì²´ ë¬¸ì„œ ê²€ìƒ‰
                            search_conditions.append({"content": {"$regex": query_lower, "$options": "i"}})
                            
                            # ë‹¨ì–´ë³„ ê²€ìƒ‰
                            query_words = query_lower.split()
                            for word in query_words:
                                if len(word) > 2:
                                    search_conditions.append({"content": {"$regex": word, "$options": "i"}})
                            
                            if search_conditions:
                                mongodb_results = list(eora_system.memories.find({
                                    "$or": search_conditions
                                }).limit(limit * 2))  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ ì ìˆ˜ ê³„ì‚° í›„ í•„í„°ë§
                                
                                # ì ìˆ˜ ê³„ì‚°
                                scored_memories = []
                                for doc in mongodb_results:
                                    content = doc.get("content", "").lower()
                                    score = 0
                                    
                                    # ì •í™•í•œ ë§¤ì¹­
                                    if query_lower in content:
                                        score += 10
                                    
                                    # ë‹¨ì–´ë³„ ë§¤ì¹­
                                    for word in query_words:
                                        if len(word) > 2 and word in content:
                                            score += 5
                                    
                                    if score > 0:
                                        result_data = {
                                            "content": doc.get("content", ""),
                                            "metadata": doc.get("metadata", {}),
                                            "timestamp": doc.get("timestamp"),
                                            "memory_id": str(doc.get("_id")),
                                            "score": score,
                                            "user_id": doc.get("user_id"),
                                            "memory_type": doc.get("memory_type")
                                        }
                                        scored_memories.append(result_data)
                                
                                # ì ìˆ˜ìˆœ ì •ë ¬ í›„ ìƒìœ„ ê²°ê³¼ ë°˜í™˜
                                scored_memories.sort(key=lambda x: x["score"], reverse=True)
                                return scored_memories[:limit]
                    
                    except Exception as e:
                        logger.error(f"MongoDB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
                    
                    # MongoDB ì‹¤íŒ¨ ì‹œ ë‚´ë¶€ ë©”ëª¨ë¦¬ì—ì„œ ê²€ìƒ‰ (fallback)
                    scored_memories = []
                    for mem_id, mem_data in self.memories.items():
                        content = mem_data["content"].lower()
                        score = 0
                        
                        if query_lower in content:
                            score += 10
                        
                        query_words = query_lower.split()
                        for word in query_words:
                            if len(word) > 2 and word in content:
                                score += 5
                        
                        if score > 0:
                            result_data = mem_data.copy()
                            result_data["score"] = score
                            result_data["memory_id"] = mem_id
                            scored_memories.append(result_data)
                    
                    scored_memories.sort(key=lambda x: x["score"], reverse=True)
                    return scored_memories[:limit]
            
            return LightweightMemoryManager()
            
        except Exception as e:
            logger.error(f"ê²½ëŸ‰ memory_manager ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _setup_collections(self):
        """ì»¬ë ‰ì…˜ ì„¤ì •"""
        if self.db is not None:
            self.memories = self.db["memories"]
            self.emotion_memories = self.db["emotion_memories"]
            self.belief_memories = self.db["belief_memories"]
            self.context_memories = self.db["context_memories"]
            self.connection_index = self.db["connection_index"]
            logger.info("âœ… ë©”ëª¨ë¦¬ ì»¬ë ‰ì…˜ ì„¤ì • ì™„ë£Œ")
    
    def is_connected(self):
        """MongoDB ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            if self.client is not None and self.db is not None and self.memories is not None:
                self.client.admin.command('ping')
                return True
            return False
        except Exception as e:
            logger.debug(f"ì—°ê²° ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False
        
    def _create_indexes(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ ìƒì„±"""
        try:
            # ê¸°ë³¸ ë©”ëª¨ë¦¬ ì¸ë±ìŠ¤
            self.memories.create_index([("user_id", 1), ("timestamp", -1)])
            self.memories.create_index([("topic", 1), ("emotion_score", -1)])
            self.memories.create_index([("connections", 1)])
            
            # ê°ì • ë©”ëª¨ë¦¬ ì¸ë±ìŠ¤
            self.emotion_memories.create_index([("emotion_label", 1), ("timestamp", -1)])
            self.emotion_memories.create_index([("emotion_score", -1)])
            
            # ì‹ ë… ë©”ëª¨ë¦¬ ì¸ë±ìŠ¤
            self.belief_memories.create_index([("belief_tags", 1), ("timestamp", -1)])
            
            # ë§¥ë½ ë©”ëª¨ë¦¬ ì¸ë±ìŠ¤
            self.context_memories.create_index([("context_keywords", 1), ("timestamp", -1)])
            
            logger.info("ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì¸ë±ìŠ¤ ìƒì„± ì˜¤ë¥˜: {str(e)}")
    
    async def save_memory(self, 
                         user_id: str,
                         user_input: str, 
                         ai_response: str,
                         consciousness_level: float = 0.0,
                         emotion_data: Dict = None,
                         belief_data: Dict = None,
                         context_data: Dict = None,
                         session_id: str = None) -> Dict:
        """ë‹¤ì°¨ì› ë©”ëª¨ë¦¬ ì €ì¥"""
        if not self.is_connected():
            logger.warning("MongoDB ì—°ê²°ì´ ì—†ì–´ ë©”ëª¨ë¦¬ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤")
            return {"success": False, "error": "no_connection"}
            
        try:
            timestamp = datetime.now()
            
            # ê¸°ë³¸ ë©”ëª¨ë¦¬ ë°ì´í„°
            memory_data = {
                "user_id": user_id,
                "timestamp": timestamp,
                "session_id": session_id or f"session_{timestamp.strftime('%Y%m%d_%H%M%S')}",
                "user_input": user_input,
                "ai_response": ai_response,
                "consciousness_level": consciousness_level,
                "emotion_score": emotion_data.get("score", 0.0) if emotion_data else 0.0,
                "emotion_label": emotion_data.get("label", "neutral") if emotion_data else "neutral",
                "belief_tags": belief_data.get("tags", []) if belief_data else [],
                "context_keywords": context_data.get("keywords", []) if context_data else [],
                "topic": self._extract_topic(user_input),
                "sub_topic": self._extract_sub_topic(user_input),
                "summary": self._generate_summary(user_input, ai_response),
                "importance_score": self._calculate_importance(user_input, ai_response, consciousness_level),
                "connections": [],
                "last_accessed": None,
                "access_count": 0,
                "forgetting_score": 1.0
            }
            
            # ë©”ëª¨ë¦¬ ì €ì¥
            result = self.memories.insert_one(memory_data)
            memory_id = str(result.inserted_id)
            
            # ê°ì • ë©”ëª¨ë¦¬ ì €ì¥
            if emotion_data and emotion_data.get("score", 0) > self.emotion_threshold:
                await self._save_emotion_memory(memory_id, emotion_data, timestamp)
            
            # ì‹ ë… ë©”ëª¨ë¦¬ ì €ì¥
            if belief_data and belief_data.get("tags"):
                await self._save_belief_memory(memory_id, belief_data, timestamp)
            
            # ë§¥ë½ ë©”ëª¨ë¦¬ ì €ì¥
            if context_data and context_data.get("keywords"):
                await self._save_context_memory(memory_id, context_data, timestamp)
            
            # ì—°ê²° ê´€ê³„ ì—…ë°ì´íŠ¸
            await self._update_connections(memory_id, user_input, ai_response)
            
            logger.info(f"ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ - ì‚¬ìš©ì: {user_id}, ID: {memory_id}")
            return {"memory_id": memory_id, "status": "saved"}
            
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            return {"error": str(e)}
    
    async def store_memory(self, content: str, memory_type: str = "general", user_id: str = None, metadata: Dict = None) -> Dict:
        """
        ë©”ëª¨ë¦¬ ì €ì¥ (í•™ìŠµëœ íŒŒì¼ ì²­í¬ ì „ìš©)
        
        Args:
            content (str): ì €ì¥í•  ë‚´ìš©
            memory_type (str): ë©”ëª¨ë¦¬ íƒ€ì… (document_chunk, conversation, general ë“±)
            user_id (str): ì‚¬ìš©ì ID
            metadata (Dict): ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            
        Returns:
            Dict: ì €ì¥ ê²°ê³¼
        """
        try:
            # ì…ë ¥ ê²€ì¦
            if not content or not isinstance(content, str):
                return {
                    "success": False,
                    "error": "ë‚´ìš©ì´ ë¹„ì–´ìˆê±°ë‚˜ ë¬¸ìì—´ì´ ì•„ë‹™ë‹ˆë‹¤",
                    "type": memory_type
                }
            
            # MongoDB ì—°ê²° í™•ì¸
            if not self.is_connected():
                error_msg = "MongoDB ì—°ê²°ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
                if not self.client:
                    error_msg += " (í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ)"
                elif self.db is None:
                    error_msg += " (ë°ì´í„°ë² ì´ìŠ¤ ì—†ìŒ)"
                elif not self.memories:
                    error_msg += " (ë©”ëª¨ë¦¬ ì»¬ë ‰ì…˜ ì—†ìŒ)"
                else:
                    error_msg += " (ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨)"
                
                logger.error(f"âŒ {error_msg} - URI: {self.mongo_uri}")
                return {
                    "success": False,
                    "error": error_msg,
                    "type": memory_type,
                    "mongo_uri": self.mongo_uri
                }
            
            timestamp = datetime.now()
            metadata = metadata or {}
            
            # ê¸°ë³¸ ë©”ëª¨ë¦¬ ë°ì´í„° êµ¬ì„±
            memory_data = {
                "user_id": user_id or "system",
                "timestamp": timestamp,
                "content": content,
                "memory_type": memory_type,
                "metadata": metadata,
                "source": metadata.get("source", "file_learning"),
                "filename": metadata.get("filename", "unknown"),
                "file_extension": metadata.get("file_extension", ""),
                "chunk_index": metadata.get("chunk_index", 0),
                "total_chunks": metadata.get("total_chunks", 1),
                "importance_score": self._calculate_content_importance(content),
                "topic": self._extract_topic(content),
                "keywords": self._extract_keywords(content),
                "last_accessed": None,
                "access_count": 0,
                "forgetting_score": 1.0,
                "created_at": timestamp.isoformat()
            }
            
            # MongoDBì— ì €ì¥
            try:
                result = self.memories.insert_one(memory_data)
                memory_id = str(result.inserted_id)
                
                # ì €ì¥ ê²€ì¦: ì‹¤ì œë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
                saved_doc = self.memories.find_one({"_id": result.inserted_id})
                if not saved_doc:
                    logger.error(f"âŒ ì €ì¥ ê²€ì¦ ì‹¤íŒ¨: ë¬¸ì„œê°€ ì‹¤ì œë¡œ ì €ì¥ë˜ì§€ ì•ŠìŒ")
                    return {
                        "success": False,
                        "error": "ì €ì¥ ê²€ì¦ ì‹¤íŒ¨: ë¬¸ì„œê°€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ",
                        "type": memory_type
                    }
                
                logger.info(f"âœ… MongoDB ì €ì¥ ë° ê²€ì¦ ì™„ë£Œ - ID: {memory_id}")
                
            except Exception as db_error:
                logger.error(f"âŒ MongoDB ì‚½ì… ì˜¤ë¥˜: {str(db_error)}")
                return {
                    "success": False,
                    "error": f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(db_error)}",
                    "type": memory_type
                }
            
            # íŒŒì¼ ì²­í¬ì˜ ê²½ìš° ì¶”ê°€ ì¸ë±ì‹±
            if memory_type == "document_chunk":
                try:
                    self._index_document_chunk_sync(memory_id, content, metadata)
                except Exception as index_error:
                    logger.warning(f"âš ï¸ ì¸ë±ì‹± ì˜¤ë¥˜ (ì €ì¥ì€ ì„±ê³µ): {str(index_error)}")
            
            logger.info(f"âœ… ë©”ëª¨ë¦¬ ì €ì¥ ì™„ë£Œ - ID: {memory_id}, íƒ€ì…: {memory_type}, ë‚´ìš©: {content[:50]}...")
            
            return {
                "success": True,
                "memory_id": memory_id, 
                "status": "saved",
                "type": memory_type,
                "content_length": len(content)
            }
            
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "type": memory_type
            }
    
    def _calculate_content_importance(self, content: str) -> float:
        """ë‚´ìš©ì˜ ì¤‘ìš”ë„ ê³„ì‚°"""
        try:
            # ê¸°ë³¸ ì ìˆ˜
            importance = 0.5
            
            # ë‚´ìš© ê¸¸ì´ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
            if len(content) > 500:
                importance += 0.2
            elif len(content) > 200:
                importance += 0.1
            
            # íŠ¹ì • í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜
            important_keywords = ["ì¤‘ìš”", "í•µì‹¬", "ê¸°ë³¸", "ì›ë¦¬", "ë°©ë²•", "ê°œë…", "ì •ì˜", "ì„¤ëª…"]
            for keyword in important_keywords:
                if keyword in content:
                    importance += 0.1
                    break
            
            # ì§ˆë¬¸ í˜•íƒœì¸ ê²½ìš° ê°€ì¤‘ì¹˜
            if "?" in content or "ë¬´ì—‡" in content or "ì–´ë–»ê²Œ" in content:
                importance += 0.1
            
            return min(importance, 1.0)
            
        except Exception:
            return 0.5
    
    def _extract_keywords(self, content: str) -> List[str]:
        """ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ê¸°ë²• ì‚¬ìš© ê°€ëŠ¥)
            words = re.findall(r'\b\w{2,}\b', content)
            # ë¹ˆë„ ê¸°ë°˜ ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
            from collections import Counter
            word_freq = Counter(words)
            return [word for word, freq in word_freq.most_common(10)]
        except Exception:
            return []
    
    def _index_document_chunk_sync(self, memory_id: str, content: str, metadata: Dict):
        """ë¬¸ì„œ ì²­í¬ ì¶”ê°€ ì¸ë±ì‹± (ë™ê¸° ë²„ì „)"""
        try:
            # ë¬¸ì„œë³„ ì²­í¬ ì¸ë±ìŠ¤ ìƒì„±
            chunk_index = {
                "memory_id": memory_id,
                "filename": metadata.get("filename", ""),
                "chunk_index": metadata.get("chunk_index", 0),
                "content_hash": hashlib.md5(content.encode()).hexdigest(),
                "indexed_at": datetime.now(),
                "searchable_content": content.lower()  # ê²€ìƒ‰ìš©
            }
            
            # ë³„ë„ ì»¬ë ‰ì…˜ì— ì €ì¥ (ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•´)
            if "document_chunks" not in self.db.list_collection_names():
                self.db.create_collection("document_chunks")
                self.db["document_chunks"].create_index([("filename", 1), ("chunk_index", 1)])
                self.db["document_chunks"].create_index([("searchable_content", "text")])
            
            self.db["document_chunks"].insert_one(chunk_index)
            logger.debug(f"ë¬¸ì„œ ì²­í¬ ì¸ë±ì‹± ì™„ë£Œ: {memory_id}")
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì²­í¬ ì¸ë±ì‹± ì˜¤ë¥˜: {str(e)}")
    
    async def recall_learned_content(self, query: str, memory_type: str = None, filename: str = None, limit: int = 5, user_id: str = None) -> List[Dict]:
        """
        í•™ìŠµëœ ë‚´ìš© íšŒìƒ
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            memory_type (str): ë©”ëª¨ë¦¬ íƒ€ì… í•„í„° (document_chunk, conversation ë“±)
            filename (str): íŒŒì¼ëª… í•„í„°
            limit (int): ê²°ê³¼ ì œí•œ
            user_id (str): ì‚¬ìš©ì ID í•„í„°
            
        Returns:
            List[Dict]: íšŒìƒëœ ë©”ëª¨ë¦¬ë“¤
        """
        if not self.is_connected():
            logger.warning("MongoDB ì—°ê²°ì´ ì—†ì–´ í•™ìŠµëœ ë‚´ìš© íšŒìƒì„ ê±´ë„ˆëœë‹ˆë‹¤")
            return []
            
        try:
            # ê¸°ë³¸ í•„í„° ì¡°ê±´ë“¤
            base_filters = []
            
            # ì‚¬ìš©ì ID í•„í„° + ê³µìœ  ë°ì´í„° í¬í•¨
            if user_id:
                # ì‚¬ìš©ì ê°œì¸ ë°ì´í„° + ê´€ë¦¬ì ê³µìœ  ë°ì´í„° ëª¨ë‘ ê²€ìƒ‰
                user_filter = {
                    "$or": [
                        {"user_id": user_id},  # ê°œì¸ ë°ì´í„°
                        {"user_id": "admin_shared", "shared_to_all": True}  # ê´€ë¦¬ì ê³µìœ  ë°ì´í„°
                    ]
                }
                base_filters.append(user_filter)
            
            # ë©”ëª¨ë¦¬ íƒ€ì… í•„í„°
            if memory_type:
                base_filters.append({"memory_type": memory_type})
            
            # íŒŒì¼ëª… í•„í„°
            if filename:
                base_filters.append({"filename": {"$regex": filename, "$options": "i"}})
            
            # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¡°ê±´ - í†µí•© ê²€ìƒ‰ ë¡œì§ (Enhanced Learning + Document Chunk)
            if query:
                search_conditions = [
                    # í…ìŠ¤íŠ¸ ë‚´ìš© ê²€ìƒ‰
                    {"content": {"$regex": query, "$options": "i"}},
                    {"response": {"$regex": query, "$options": "i"}},
                    {"message": {"$regex": query, "$options": "i"}},
                    
                    # í‚¤ì›Œë“œ ë° íƒœê·¸ ê²€ìƒ‰ (ë°°ì—´ í•„ë“œ ê°œì„ )
                    {"keywords": {"$elemMatch": {"$regex": query, "$options": "i"}}},
                    {"tags": {"$elemMatch": {"$regex": query, "$options": "i"}}},
                    {"keywords": {"$in": [query]}},  # ì •í™• ì¼ì¹˜ë„ í¬í•¨
                    {"tags": {"$in": [query]}},
                    
                    # ì¹´í…Œê³ ë¦¬ ë° ì£¼ì œ ê²€ìƒ‰
                    {"category": {"$regex": query, "$options": "i"}},
                    {"topic": {"$regex": query, "$options": "i"}},
                    
                    # íŒŒì¼ëª… ê²€ìƒ‰ (Enhanced Learning + Document Chunk í˜¸í™˜)
                    {"filename": {"$regex": query, "$options": "i"}},
                    {"source_file": {"$regex": query, "$options": "i"}},
                    {"metadata.filename": {"$regex": query, "$options": "i"}},  # Document Chunkìš©
                    
                    # ì†ŒìŠ¤ ë° ë©”íƒ€ë°ì´í„° ê²€ìƒ‰
                    {"source": {"$regex": query, "$options": "i"}},
                    {"upload_type": {"$regex": query, "$options": "i"}},
                    {"metadata.source": {"$regex": query, "$options": "i"}},  # Document Chunkìš©
                    {"metadata.upload_type": {"$regex": query, "$options": "i"}},  # Document Chunkìš©
                    
                    # Document Chunk ì „ìš© ë©”íƒ€ë°ì´í„° ê²€ìƒ‰
                    {"metadata.file_extension": {"$regex": query, "$options": "i"}},
                    {"metadata.uploader_email": {"$regex": query, "$options": "i"}}
                ]
                base_filters.append({"$or": search_conditions})
            
            # ìµœì¢… ê²€ìƒ‰ ì¿¼ë¦¬ ì¡°í•©
            if base_filters:
                search_query = {"$and": base_filters} if len(base_filters) > 1 else base_filters[0]
            else:
                search_query = {}
            
            # MongoDBì—ì„œ í†µí•© ê²€ìƒ‰ ì‹¤í–‰
            logger.info(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {search_query}")
            
            # í†µí•© ê²€ìƒ‰: Enhanced Learning + Document Chunk ëª¨ë‘ ê²€ìƒ‰
            all_results = []
            
            # 1ë‹¨ê³„: Enhanced Learning ë°ì´í„° ê²€ìƒ‰
            enhanced_query = search_query.copy() if search_query else {}
            enhanced_query["memory_type"] = "enhanced_learning"
            
            enhanced_cursor = self.memories.find(enhanced_query).sort([
                ("shared_to_all", -1),  # ê³µìœ  ë°ì´í„° ìš°ì„ 
                ("timestamp", -1)       # ìµœì‹ ìˆœ
            ]).limit(limit)
            enhanced_results = list(enhanced_cursor)
            all_results.extend(enhanced_results)
            logger.info(f"ğŸ¯ Enhanced Learning ê²€ìƒ‰ ê²°ê³¼: {len(enhanced_results)}ê°œ")
            
            # 2ë‹¨ê³„: Document Chunk ë°ì´í„° ê²€ìƒ‰ (ê¸°ì¡´ APIë¡œ ì €ì¥ëœ ë°ì´í„°)
            remaining_limit = max(0, limit - len(enhanced_results))
            if remaining_limit > 0:
                # ê¸°ì¡´ ID ì œì™¸
                existing_ids = [r["_id"] for r in enhanced_results]
                
                document_query = search_query.copy() if search_query else {}
                document_query["memory_type"] = "document_chunk"
                if existing_ids:
                    document_query["_id"] = {"$nin": existing_ids}
                
                document_cursor = self.memories.find(document_query).sort([
                    ("metadata.shared_to_all", -1),  # ë©”íƒ€ë°ì´í„°ì˜ ê³µìœ  í”Œë˜ê·¸
                    ("timestamp", -1)
                ]).limit(remaining_limit)
                document_results = list(document_cursor)
                all_results.extend(document_results)
                logger.info(f"ğŸ“„ Document Chunk ê²€ìƒ‰ ê²°ê³¼: {len(document_results)}ê°œ")
            
            # 3ë‹¨ê³„: ì—¬ì „íˆ ë¶€ì¡±í•˜ë©´ ë‹¤ë¥¸ íƒ€ì…ë„ ê²€ìƒ‰
            remaining_limit = max(0, limit - len(all_results))
            if remaining_limit > 0:
                existing_ids = [r["_id"] for r in all_results]
                
                other_query = search_query.copy() if search_query else {}
                other_query["memory_type"] = {"$nin": ["enhanced_learning", "document_chunk"]}
                if existing_ids:
                    other_query["_id"] = {"$nin": existing_ids}
                
                other_cursor = self.memories.find(other_query).sort([
                    ("timestamp", -1)
                ]).limit(remaining_limit)
                other_results = list(other_cursor)
                all_results.extend(other_results)
                logger.info(f"ğŸ“š ê¸°íƒ€ íƒ€ì… ê²€ìƒ‰ ê²°ê³¼: {len(other_results)}ê°œ")
            
            results = all_results
            logger.info(f"ğŸ“š ì´ ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
            
            # ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
            if query and results:
                query_lower = query.lower()
                for result in results:
                    score = 0
                    content = result.get("content", result.get("response", "")).lower()
                    keywords = result.get("keywords", result.get("tags", []))
                    topic = result.get("topic", result.get("category", "")).lower()
                    filename = result.get("filename", result.get("source_file", "")).lower()
                    
                    # ì •í™•í•œ ë§¤ì¹˜ì— ë†’ì€ ì ìˆ˜
                    if query_lower in content:
                        score += 3
                    if query_lower in topic:
                        score += 2
                    if query_lower in filename:
                        score += 2
                    if any(query_lower in str(kw).lower() for kw in keywords):
                        score += 2
                    
                    # ë¶€ë¶„ ë§¤ì¹˜ì— ë‚®ì€ ì ìˆ˜
                    query_words = query_lower.split()
                    for word in query_words:
                        if word in content:
                            score += 1
                        if word in topic:
                            score += 0.5
                    
                    result["relevance_score"] = score
                
                # ê´€ë ¨ì„± ì ìˆ˜ë¡œ ì •ë ¬
                results.sort(key=lambda x: x.get("relevance_score", 0), reverse=True)
                results = results[:limit]
            
            # ObjectIdë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            for result in results:
                if "_id" in result:
                    result["_id"] = str(result["_id"])
                if "timestamp" in result and hasattr(result["timestamp"], "isoformat"):
                    result["timestamp"] = result["timestamp"].isoformat()
            
            logger.info(f"âœ… í•™ìŠµ ë‚´ìš© íšŒìƒ ì™„ë£Œ - ì¿¼ë¦¬: '{query}', ê²°ê³¼: {len(results)}ê°œ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ ë‚´ìš© íšŒìƒ ì˜¤ë¥˜: {str(e)}")
            return []
    
    async def get_learned_files_list(self) -> List[Dict]:
        """í•™ìŠµëœ íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
        if not self.is_connected():
            logger.warning("MongoDB ì—°ê²°ì´ ì—†ì–´ í•™ìŠµëœ íŒŒì¼ ëª©ë¡ ì¡°íšŒë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
            return []
            
        try:
            # íŒŒì¼ë³„ ì²­í¬ ê°œìˆ˜ ì§‘ê³„
            pipeline = [
                {"$match": {"memory_type": "document_chunk"}},
                {"$group": {
                    "_id": "$filename",
                    "chunk_count": {"$sum": 1},
                    "latest_timestamp": {"$max": "$timestamp"},
                    "file_extension": {"$first": "$file_extension"}
                }},
                {"$sort": {"latest_timestamp": -1}}
            ]
            
            results = list(self.memories.aggregate(pipeline))
            
            # ê²°ê³¼ í¬ë§·íŒ…
            file_list = []
            for result in results:
                file_info = {
                    "filename": result["_id"],
                    "chunk_count": result["chunk_count"],
                    "file_extension": result.get("file_extension", ""),
                    "latest_timestamp": result["latest_timestamp"].isoformat() if hasattr(result["latest_timestamp"], "isoformat") else str(result["latest_timestamp"])
                }
                file_list.append(file_info)
            
            logger.info(f"âœ… í•™ìŠµëœ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ - {len(file_list)}ê°œ íŒŒì¼")
            return file_list
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµëœ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return []
    
    async def get_learning_statistics(self) -> Dict:
        """í•™ìŠµ í†µê³„ ì¡°íšŒ"""
        if not self.is_connected():
            logger.warning("MongoDB ì—°ê²°ì´ ì—†ì–´ í•™ìŠµ í†µê³„ ì¡°íšŒë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
            return {
                "total_memories": 0,
                "document_chunks": 0,
                "conversations": 0,
                "file_count": 0,
                "connection_status": "disconnected"
            }
            
        try:
            # ì „ì²´ ë©”ëª¨ë¦¬ ìˆ˜
            total_memories = self.memories.count_documents({})
            
            # ë¬¸ì„œ ì²­í¬ ìˆ˜
            document_chunks = self.memories.count_documents({"memory_type": "document_chunk"})
            
            # ëŒ€í™” ê¸°ë¡ ìˆ˜
            conversations = self.memories.count_documents({"memory_type": "conversation"})
            
            # íŒŒì¼ë³„ í†µê³„
            file_stats = await self.get_learned_files_list()
            
            # ìµœê·¼ í•™ìŠµ í™œë™
            recent_learning = list(self.memories.find({}).sort("timestamp", -1).limit(10))
            for item in recent_learning:
                if "_id" in item:
                    item["_id"] = str(item["_id"])
                if "timestamp" in item and hasattr(item["timestamp"], "isoformat"):
                    item["timestamp"] = item["timestamp"].isoformat()
            
            statistics = {
                "total_memories": total_memories,
                "document_chunks": document_chunks,
                "conversations": conversations,
                "learned_files_count": len(file_stats),
                "learned_files": file_stats,
                "recent_learning": recent_learning
            }
            
            logger.info(f"âœ… í•™ìŠµ í†µê³„ ì¡°íšŒ ì™„ë£Œ")
            return statistics
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {
                "total_memories": 0,
                "document_chunks": 0,
                "conversations": 0,
                "learned_files_count": 0,
                "learned_files": [],
                "recent_learning": []
            }
    
    async def _save_emotion_memory(self, memory_id: str, emotion_data: Dict, timestamp: datetime):
        """ê°ì • ë©”ëª¨ë¦¬ ì €ì¥"""
        emotion_memory = {
            "memory_id": memory_id,
            "timestamp": timestamp,
            "emotion_label": emotion_data.get("label", "neutral"),
            "emotion_score": emotion_data.get("score", 0.0),
            "emotion_intensity": emotion_data.get("intensity", 0.0),
            "emotion_context": emotion_data.get("context", ""),
            "valence": emotion_data.get("valence", 0.0),
            "arousal": emotion_data.get("arousal", 0.0)
        }
        self.emotion_memories.insert_one(emotion_memory)
    
    async def _save_belief_memory(self, memory_id: str, belief_data: Dict, timestamp: datetime):
        """ì‹ ë… ë©”ëª¨ë¦¬ ì €ì¥"""
        belief_memory = {
            "memory_id": memory_id,
            "timestamp": timestamp,
            "belief_tags": belief_data.get("tags", []),
            "belief_strength": belief_data.get("strength", 0.0),
            "belief_context": belief_data.get("context", ""),
            "belief_type": belief_data.get("type", "general")
        }
        self.belief_memories.insert_one(belief_memory)
    
    async def _save_context_memory(self, memory_id: str, context_data: Dict, timestamp: datetime):
        """ë§¥ë½ ë©”ëª¨ë¦¬ ì €ì¥"""
        context_memory = {
            "memory_id": memory_id,
            "timestamp": timestamp,
            "context_keywords": context_data.get("keywords", []),
            "context_type": context_data.get("type", "general"),
            "context_importance": context_data.get("importance", 0.0),
            "context_relations": context_data.get("relations", [])
        }
        self.context_memories.insert_one(context_memory)
    
    async def recall_memories(self, 
                            user_id: str,
                            query: str,
                            recall_type: str = "comprehensive",
                            limit: int = None) -> List[Dict]:
        """ë‹¤ì¤‘ ì „ëµ ë©”ëª¨ë¦¬ íšŒìƒ"""
        try:
            limit = limit or self.recall_limit
            recalled_memories = []
            
            if recall_type == "comprehensive":
                # ì¢…í•© íšŒìƒ: ëª¨ë“  ì „ëµ ì‚¬ìš©
                recalled_memories = await self._comprehensive_recall(user_id, query, limit)
            elif recall_type == "emotion":
                # ê°ì • ê¸°ë°˜ íšŒìƒ
                recalled_memories = await self._emotion_based_recall(user_id, query, limit)
            elif recall_type == "context":
                # ë§¥ë½ ê¸°ë°˜ íšŒìƒ
                recalled_memories = await self._context_based_recall(user_id, query, limit)
            elif recall_type == "belief":
                # ì‹ ë… ê¸°ë°˜ íšŒìƒ
                recalled_memories = await self._belief_based_recall(user_id, query, limit)
            elif recall_type == "semantic":
                # ì˜ë¯¸ ê¸°ë°˜ íšŒìƒ
                recalled_memories = await self._semantic_recall(user_id, query, limit)
            else:
                # ê¸°ë³¸ í‚¤ì›Œë“œ ê¸°ë°˜ íšŒìƒ
                recalled_memories = await self._keyword_recall(user_id, query, limit)
            
            # íšŒìƒ ê²°ê³¼ ì •ì œ ë° ì •ë ¬
            cleaned_memories = self._clean_recall_results(recalled_memories)
            sorted_memories = self._sort_recall_results(cleaned_memories, query)
            
            # ì ‘ê·¼ ê¸°ë¡ ì—…ë°ì´íŠ¸
            await self._update_access_records([m["_id"] for m in sorted_memories])
            
            logger.info(f"ë©”ëª¨ë¦¬ íšŒìƒ ì™„ë£Œ - ì‚¬ìš©ì: {user_id}, ì¿¼ë¦¬: {query}, ê²°ê³¼: {len(sorted_memories)}ê°œ")
            return sorted_memories
            
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ íšŒìƒ ì˜¤ë¥˜: {str(e)}")
            return []
    
    async def enhanced_recall(self, query: str, user_id: str, limit: int = 5) -> List[Dict]:
        """
        í–¥ìƒëœ íšŒìƒ ì‹œìŠ¤í…œ - í•™ìŠµëœ ë‚´ìš©(ì „ì²´ ê³µìœ ) + ê°œì¸ ëŒ€í™” ê¸°ë¡ ê²°í•©
        
        Args:
            query (str): ê²€ìƒ‰ ì¿¼ë¦¬
            user_id (str): ì‚¬ìš©ì ID (ê°œì¸ ëŒ€í™” ê¸°ë¡ìš©)
            limit (int): ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: íšŒìƒëœ ë©”ëª¨ë¦¬ ëª©ë¡
        """
        if not self.is_connected():
            logger.warning("MongoDB ì—°ê²°ì´ ì—†ì–´ ë©”ëª¨ë¦¬ íšŒìƒì„ ê±´ë„ˆëœë‹ˆë‹¤")
            return []
            
        try:
            all_memories = []
            
            # 1. í•™ìŠµëœ ë‚´ìš© íšŒìƒ (ëª¨ë“  ì‚¬ìš©ì ê³µìœ )
            # document_chunk íƒ€ì…ì€ ê´€ë¦¬ìê°€ í•™ìŠµí•œ ë‚´ìš©ìœ¼ë¡œ ëª¨ë“  ì‚¬ìš©ìê°€ ê³µìœ 
            learned_memories = await self.recall_learned_content(
                query=query,
                memory_type="document_chunk",
                limit=max(3, limit // 2)  # ì „ì²´ í•œë„ì˜ ì ˆë°˜ ì´ìƒì„ í•™ìŠµ ë‚´ìš©ì— í• ë‹¹
            )
            
            if learned_memories:
                # í•™ìŠµëœ ë‚´ìš©ì— í‘œì‹œ ì¶”ê°€
                for memory in learned_memories:
                    memory["recall_type"] = "learned_content"
                    memory["is_shared"] = True
                all_memories.extend(learned_memories)
                logger.info(f"ğŸ“š í•™ìŠµëœ ë‚´ìš© íšŒìƒ: {len(learned_memories)}ê°œ")
            
            # 2. ê°œì¸ ëŒ€í™” ê¸°ë¡ íšŒìƒ (ì‚¬ìš©ìë³„)
            personal_limit = limit - len(learned_memories)
            if personal_limit > 0:
                personal_memories = await self.recall_memories(
                    user_id=user_id,
                    query=query,
                    recall_type="comprehensive",
                    limit=personal_limit
                )
                
                if personal_memories:
                    # ê°œì¸ ëŒ€í™” ë‚´ìš©ì— í‘œì‹œ ì¶”ê°€
                    for memory in personal_memories:
                        memory["recall_type"] = "personal_conversation"
                        memory["is_shared"] = False
                    all_memories.extend(personal_memories)
                    logger.info(f"ğŸ‘¤ ê°œì¸ ëŒ€í™” íšŒìƒ: {len(personal_memories)}ê°œ")
            
            # 3. ê²°ê³¼ ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
            # ê´€ë ¨ì„± ì ìˆ˜ì™€ ì¤‘ìš”ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            unique_memories = {}
            for memory in all_memories:
                memory_id = str(memory.get("_id", ""))
                if memory_id not in unique_memories:
                    unique_memories[memory_id] = memory
            
            final_memories = list(unique_memories.values())
            
            # í•™ìŠµëœ ë‚´ìš©ì„ ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
            final_memories.sort(key=lambda x: (
                x.get("is_shared", False),  # í•™ìŠµëœ ë‚´ìš© ìš°ì„ 
                x.get("importance_score", 0),  # ì¤‘ìš”ë„ ì ìˆ˜
                x.get("relevance_score", 0)  # ê´€ë ¨ì„± ì ìˆ˜
            ), reverse=True)
            
            # í•œë„ ì ìš©
            final_memories = final_memories[:limit]
            
            logger.info(f"âœ… í†µí•© íšŒìƒ ì™„ë£Œ - ì´ {len(final_memories)}ê°œ (í•™ìŠµ: {len(learned_memories)}, ê°œì¸: {len(all_memories) - len(learned_memories)})")
            return final_memories
            
        except Exception as e:
            logger.error(f"âŒ í–¥ìƒëœ íšŒìƒ ì˜¤ë¥˜: {str(e)}")
            return []
    
    async def _comprehensive_recall(self, user_id: str, query: str, limit: int) -> List[Dict]:
        """ì¢…í•© íšŒìƒ ì „ëµ"""
        all_memories = []
        
        # 1. ê°ì • ê¸°ë°˜ íšŒìƒ
        emotion_memories = await self._emotion_based_recall(user_id, query, limit // 3)
        all_memories.extend(emotion_memories)
        
        # 2. ë§¥ë½ ê¸°ë°˜ íšŒìƒ
        context_memories = await self._context_based_recall(user_id, query, limit // 3)
        all_memories.extend(context_memories)
        
        # 3. ì˜ë¯¸ ê¸°ë°˜ íšŒìƒ
        semantic_memories = await self._semantic_recall(user_id, query, limit // 3)
        all_memories.extend(semantic_memories)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        unique_memories = self._remove_duplicates(all_memories)
        return unique_memories[:limit]
    
    async def _emotion_based_recall(self, user_id: str, query: str, limit: int) -> List[Dict]:
        """ê°ì • ê¸°ë°˜ íšŒìƒ"""
        # ì¿¼ë¦¬ì—ì„œ ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        emotion_keywords = self._extract_emotion_keywords(query)
        
        if not emotion_keywords:
            return []
        
        # ê°ì • ë©”ëª¨ë¦¬ì—ì„œ ê²€ìƒ‰
        emotion_query = {
            "emotion_label": {"$in": emotion_keywords},
            "user_id": user_id
        }
        
        memories = list(self.memories.find(emotion_query)
                       .sort([("emotion_score", -1), ("timestamp", -1)])
                       .limit(limit))
        
        return memories
    
    async def _context_based_recall(self, user_id: str, query: str, limit: int) -> List[Dict]:
        """ë§¥ë½ ê¸°ë°˜ íšŒìƒ"""
        # ì¿¼ë¦¬ì—ì„œ ë§¥ë½ í‚¤ì›Œë“œ ì¶”ì¶œ
        context_keywords = self._extract_context_keywords(query)
        
        if not context_keywords:
            return []
        
        # ë§¥ë½ ë©”ëª¨ë¦¬ì—ì„œ ê²€ìƒ‰
        context_query = {
            "context_keywords": {"$in": context_keywords},
            "user_id": user_id
        }
        
        memories = list(self.memories.find(context_query)
                       .sort([("importance_score", -1), ("timestamp", -1)])
                       .limit(limit))
        
        return memories
    
    async def _belief_based_recall(self, user_id: str, query: str, limit: int) -> List[Dict]:
        """ì‹ ë… ê¸°ë°˜ íšŒìƒ"""
        # ì¿¼ë¦¬ì—ì„œ ì‹ ë… í‚¤ì›Œë“œ ì¶”ì¶œ
        belief_keywords = self._extract_belief_keywords(query)
        
        if not belief_keywords:
            return []
        
        # ì‹ ë… ë©”ëª¨ë¦¬ì—ì„œ ê²€ìƒ‰
        belief_query = {
            "belief_tags": {"$in": belief_keywords},
            "user_id": user_id
        }
        
        memories = list(self.memories.find(belief_query)
                       .sort([("importance_score", -1), ("timestamp", -1)])
                       .limit(limit))
        
        return memories
    
    async def _semantic_recall(self, user_id: str, query: str, limit: int) -> List[Dict]:
        """ì˜ë¯¸ ê¸°ë°˜ íšŒìƒ"""
        # ì¿¼ë¦¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        query_keywords = self._extract_keywords(query)
        
        if not query_keywords:
            return []
        
        # ì˜ë¯¸ì  ìœ ì‚¬ì„± ê²€ìƒ‰
        semantic_query = {
            "user_id": user_id,
            "$or": [
                {"user_input": {"$regex": "|".join(query_keywords), "$options": "i"}},
                {"ai_response": {"$regex": "|".join(query_keywords), "$options": "i"}},
                {"summary": {"$regex": "|".join(query_keywords), "$options": "i"}}
            ]
        }
        
        memories = list(self.memories.find(semantic_query)
                       .sort([("importance_score", -1), ("timestamp", -1)])
                       .limit(limit))
        
        return memories
    
    async def _keyword_recall(self, user_id: str, query: str, limit: int) -> List[Dict]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ íšŒìƒ"""
        query_keywords = self._extract_keywords(query)
        
        if not query_keywords:
            return []
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰
        keyword_query = {
            "user_id": user_id,
            "$or": [
                {"user_input": {"$regex": "|".join(query_keywords), "$options": "i"}},
                {"ai_response": {"$regex": "|".join(query_keywords), "$options": "i"}},
                {"topic": {"$regex": "|".join(query_keywords), "$options": "i"}},
                {"sub_topic": {"$regex": "|".join(query_keywords), "$options": "i"}}
            ]
        }
        
        memories = list(self.memories.find(keyword_query)
                       .sort([("importance_score", -1), ("timestamp", -1)])
                       .limit(limit))
        
        return memories
    
    def _extract_emotion_keywords(self, text: str) -> List[str]:
        """ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ"""
        emotion_keywords = [
            "ê¸°ì¨", "í–‰ë³µ", "ì¦ê±°ì›€", "ë§Œì¡±", "ê°ì‚¬", "ì‚¬ë‘", "í¬ë§", "ì—´ì •",
            "ìŠ¬í””", "ìš°ìš¸", "ì ˆë§", "ì™¸ë¡œì›€", "ê·¸ë¦¬ì›€", "ì•„í””", "ìƒì‹¤",
            "ë¶„ë…¸", "í™”ë‚¨", "ì§œì¦", "ë¶ˆë§Œ", "ì ëŒ€ê°", "ì›ë§",
            "ë¶ˆì•ˆ", "ê±±ì •", "ë‘ë ¤ì›€", "ê¸´ì¥", "ìŠ¤íŠ¸ë ˆìŠ¤", "ì••ë°•ê°",
            "ë†€ëŒ", "ì¶©ê²©", "ë‹¹í™©", "í˜¼ë€", "ì˜ì•„í•¨",
            "í‰ì˜¨", "ì°¨ë¶„", "ì—¬ìœ ", "ì•ˆì •", "í¸ì•ˆ"
        ]
        
        found_emotions = []
        for emotion in emotion_keywords:
            if emotion in text:
                found_emotions.append(emotion)
        
        return found_emotions
    
    def _extract_context_keywords(self, text: str) -> List[str]:
        """ë§¥ë½ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        context_patterns = [
            r"ì§‘ì—ì„œ", r"íšŒì‚¬ì—ì„œ", r"í•™êµì—ì„œ", r"ì¹´í˜ì—ì„œ", r"ê¸¸ì—ì„œ",
            r"ì•„ì¹¨ì—", r"ì ì‹¬ì—", r"ì €ë…ì—", r"ë°¤ì—", r"ìƒˆë²½ì—",
            r"ì¹œêµ¬ì™€", r"ê°€ì¡±ê³¼", r"ë™ë£Œì™€", r"ì„ ìƒë‹˜ê³¼", r"ì˜ì‚¬ì™€",
            r"ì½”ë”©", r"í”„ë¡œê·¸ë˜ë°", r"ê°œë°œ", r"í•™ìŠµ", r"ê³µë¶€",
            r"ìŒì•…", r"ì˜í™”", r"ì±…", r"ìš´ë™", r"ìš”ë¦¬"
        ]
        
        context_keywords = []
        for pattern in context_patterns:
            matches = re.findall(pattern, text)
            context_keywords.extend(matches)
        
        return list(set(context_keywords))
    
    def _extract_belief_keywords(self, text: str) -> List[str]:
        """ì‹ ë… í‚¤ì›Œë“œ ì¶”ì¶œ"""
        belief_keywords = [
            "ë¯¿ìŒ", "ì‹ ë…", "ê°€ì¹˜ê´€", "ì² í•™", "ì›ì¹™", "ë„ë•", "ìœ¤ë¦¬",
            "ì •ì˜", "í‰ë“±", "ììœ ", "ì±…ì„", "ì„±ì‹¤", "ì •ì§", "ìš©ê¸°",
            "ì¸ë‚´", "ê²¸ì†", "ë°°ë ¤", "ì¡´ì¤‘", "ì‚¬ë‘", "í¬ìƒ", "ë´‰ì‚¬"
        ]
        
        found_beliefs = []
        for belief in belief_keywords:
            if belief in text:
                found_beliefs.append(belief)
        
        return found_beliefs
    
    def _extract_keywords(self, text: str) -> List[str]:
        """ì¼ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ë¶ˆìš©ì–´ ì œê±°
        stop_words = ["ì´", "ê°€", "ì„", "ë¥¼", "ì˜", "ì—", "ì—ì„œ", "ë¡œ", "ìœ¼ë¡œ", "ì™€", "ê³¼", "ë„", "ë§Œ", "ì€", "ëŠ”", "ì´", "ê·¸", "ì €", "ìš°ë¦¬", "ë„ˆ", "ë‚˜"]
        
        # ë‹¨ì–´ ë¶„ë¦¬ ë° í•„í„°ë§
        words = re.findall(r'\w+', text)
        keywords = [word for word in words if len(word) > 1 and word not in stop_words]
        
        return keywords[:10]  # ìƒìœ„ 10ê°œ í‚¤ì›Œë“œë§Œ ë°˜í™˜
    
    def _extract_topic(self, text: str) -> str:
        """ì£¼ì œ ì¶”ì¶œ"""
        topics = {
            "ê°ì •": ["ê¸°ë¶„", "ëŠë‚Œ", "ê°ì •", "ë§ˆìŒ", "ì‹¬ì •"],
            "ì¼ìƒ": ["ì¼", "ìƒí™œ", "ë£¨í‹´", "í•˜ë£¨", "ì¼ìƒ"],
            "ê´€ê³„": ["ì¹œêµ¬", "ê°€ì¡±", "ì‚¬ëŒ", "ê´€ê³„", "ëŒ€í™”"],
            "í•™ìŠµ": ["ê³µë¶€", "í•™ìŠµ", "ë°°ìš°", "ì§€ì‹", "êµìœ¡"],
            "ê¸°ìˆ ": ["ì½”ë”©", "í”„ë¡œê·¸ë˜ë°", "ê°œë°œ", "ê¸°ìˆ ", "ì½”ë“œ"],
            "ì² í•™": ["ì˜ë¯¸", "ì¡´ì¬", "ìƒëª…", "ìš°ì£¼", "ì§„ë¦¬", "ì² í•™"],
            "ê±´ê°•": ["ê±´ê°•", "ìš´ë™", "ë³‘", "ì˜ì‚¬", "ì•½"],
            "ì·¨ë¯¸": ["ì·¨ë¯¸", "ê´€ì‹¬", "ì¢‹ì•„", "ì¦ê²¨", "ì¬ë¯¸"]
        }
        
        for topic, keywords in topics.items():
            if any(keyword in text for keyword in keywords):
                return topic
        
        return "ì¼ë°˜"
    
    def _extract_sub_topic(self, text: str) -> str:
        """í•˜ìœ„ ì£¼ì œ ì¶”ì¶œ"""
        # ë” êµ¬ì²´ì ì¸ í•˜ìœ„ ì£¼ì œ ì¶”ì¶œ ë¡œì§
        return "ì¼ë°˜"
    
    def _generate_summary(self, user_input: str, ai_response: str) -> str:
        """ë©”ëª¨ë¦¬ ìš”ì•½ ìƒì„±"""
        # ê°„ë‹¨í•œ ìš”ì•½ ìƒì„± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ìš”ì•½ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
        combined = f"{user_input} â†’ {ai_response}"
        if len(combined) > 200:
            return combined[:200] + "..."
        return combined
    
    def _calculate_importance(self, user_input: str, ai_response: str, consciousness_level: float) -> float:
        """ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°"""
        importance = 0.5  # ê¸°ë³¸ ì ìˆ˜
        
        # ì˜ì‹ ìˆ˜ì¤€ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
        importance += consciousness_level * 0.3
        
        # ê°ì • í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°€ì¤‘ì¹˜ ì¦ê°€
        if self._extract_emotion_keywords(user_input):
            importance += 0.2
        
        # ì² í•™ì  í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê°€ì¤‘ì¹˜ ì¦ê°€
        if any(word in user_input for word in ["ì˜ë¯¸", "ì¡´ì¬", "ìƒëª…", "ìš°ì£¼", "ì§„ë¦¬"]):
            importance += 0.3
        
        # ì‘ë‹µ ê¸¸ì´ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
        if len(ai_response) > 100:
            importance += 0.1
        
        return min(1.0, importance)
    
    async def _update_connections(self, memory_id: str, user_input: str, ai_response: str):
        """ì—°ê²° ê´€ê³„ ì—…ë°ì´íŠ¸"""
        # ìœ ì‚¬í•œ ë©”ëª¨ë¦¬ë“¤ê³¼ì˜ ì—°ê²° ìƒì„±
        similar_memories = await self._find_similar_memories(user_input, ai_response)
        
        if similar_memories:
            # í˜„ì¬ ë©”ëª¨ë¦¬ì— ì—°ê²° ì •ë³´ ì¶”ê°€
            self.memories.update_one(
                {"_id": ObjectId(memory_id)},
                {"$set": {"connections": [str(m["_id"]) for m in similar_memories]}}
            )
    
    async def _find_similar_memories(self, user_input: str, ai_response: str) -> List[Dict]:
        """ìœ ì‚¬í•œ ë©”ëª¨ë¦¬ ì°¾ê¸°"""
        # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê²€ìƒ‰ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
        keywords = self._extract_keywords(user_input)
        
        if not keywords:
            return []
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ ë©”ëª¨ë¦¬ ê²€ìƒ‰
        similar_query = {
            "$or": [
                {"user_input": {"$regex": "|".join(keywords[:3]), "$options": "i"}},
                {"ai_response": {"$regex": "|".join(keywords[:3]), "$options": "i"}}
            ]
        }
        
        similar_memories = list(self.memories.find(similar_query)
                              .sort("timestamp", -1)
                              .limit(5))
        
        return similar_memories
    
    def _clean_recall_results(self, memories: List[Dict]) -> List[Dict]:
        """íšŒìƒ ê²°ê³¼ ì •ì œ"""
        cleaned = []
        
        for memory in memories:
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            if not all(key in memory for key in ["user_input", "ai_response", "timestamp"]):
                continue
            
            # ë¹ˆ ë‚´ìš© ì œê±°
            if not memory["user_input"].strip() or not memory["ai_response"].strip():
                continue
            
            # ë„ˆë¬´ ì˜¤ë˜ëœ ë©”ëª¨ë¦¬ ì œê±° (1ë…„ ì´ìƒ)
            memory_date = memory["timestamp"]
            if isinstance(memory_date, str):
                memory_date = datetime.fromisoformat(memory_date.replace('Z', '+00:00'))
            
            if memory_date < datetime.now() - timedelta(days=365):
                continue
            
            cleaned.append(memory)
        
        return cleaned
    
    def _sort_recall_results(self, memories: List[Dict], query: str) -> List[Dict]:
        """íšŒìƒ ê²°ê³¼ ì •ë ¬"""
        def sort_key(memory):
            score = 0.0
            
            # ì¤‘ìš”ë„ ì ìˆ˜
            score += memory.get("importance_score", 0.0) * 0.4
            
            # ìµœê·¼ì„± ì ìˆ˜
            memory_date = memory["timestamp"]
            if isinstance(memory_date, str):
                memory_date = datetime.fromisoformat(memory_date.replace('Z', '+00:00'))
            
            days_old = (datetime.now() - memory_date).days
            recency_score = max(0, 1 - (days_old / 365))
            score += recency_score * 0.3
            
            # ì ‘ê·¼ ë¹ˆë„ ì ìˆ˜
            access_count = memory.get("access_count", 0)
            score += min(1.0, access_count / 10) * 0.2
            
            # ì¿¼ë¦¬ ê´€ë ¨ì„± ì ìˆ˜
            query_keywords = self._extract_keywords(query)
            memory_text = f"{memory['user_input']} {memory['ai_response']}"
            relevance_score = sum(1 for keyword in query_keywords if keyword in memory_text) / len(query_keywords) if query_keywords else 0
            score += relevance_score * 0.1
            
            return score
        
        return sorted(memories, key=sort_key, reverse=True)
    
    async def _update_access_records(self, memory_ids: List[str]):
        """ì ‘ê·¼ ê¸°ë¡ ì—…ë°ì´íŠ¸"""
        for memory_id in memory_ids:
            self.memories.update_one(
                {"_id": ObjectId(memory_id)},
                {
                    "$set": {"last_accessed": datetime.now()},
                    "$inc": {"access_count": 1}
                }
            )
    
    def _remove_duplicates(self, memories: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ë©”ëª¨ë¦¬ ì œê±°"""
        seen_ids = set()
        unique_memories = []
        
        for memory in memories:
            memory_id = str(memory["_id"])
            if memory_id not in seen_ids:
                seen_ids.add(memory_id)
                unique_memories.append(memory)
        
        return unique_memories
    
    async def get_memory_stats(self, user_id: str) -> Dict:
        """ë©”ëª¨ë¦¬ í†µê³„ ì¡°íšŒ"""
        try:
            total_memories = self.memories.count_documents({"user_id": user_id})
            
            # ê°ì •ë³„ í†µê³„
            emotion_stats = list(self.memories.aggregate([
                {"$match": {"user_id": user_id}},
                {"$group": {"_id": "$emotion_label", "count": {"$sum": 1}}},
                {"$sort": {"count": -1}}
            ]))
            
            # ì£¼ì œë³„ í†µê³„
            topic_stats = list(self.memories.aggregate([
                {"$match": {"user_id": user_id}},
                {"$group": {"_id": "$topic", "count": {"$sum": 1}}},
                {"$sort": {"count": -1}}
            ]))
            
            # ìµœê·¼ ë©”ëª¨ë¦¬
            recent_memories = list(self.memories.find({"user_id": user_id})
                                 .sort("timestamp", -1)
                                 .limit(5))
            
            return {
                "total_memories": total_memories,
                "emotion_stats": emotion_stats,
                "topic_stats": topic_stats,
                "recent_memories": recent_memories
            }
            
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {"error": str(e)}
    
    # ===================== íšŒìƒ ê¸°ëŠ¥ ë©”ì„œë“œë“¤ =====================
    
    async def enhanced_recall(self, query: str, user_id: str = None, limit: int = 5):
        """í–¥ìƒëœ íšŒìƒ ê¸°ëŠ¥ - RecallEngine ë˜ëŠ” ê²½ëŸ‰ memory_manager í™œìš©"""
        if not self.memory_manager or not self.memory_manager.is_initialized:
            logger.warning("memory_managerê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ê¸°ë³¸ íšŒìƒ ì‚¬ìš©")
            return await self._basic_recall(query, user_id, limit)
        
        try:
            # ê²½ëŸ‰ memory_managerì¸ì§€ í™•ì¸
            manager_type = type(self.memory_manager).__name__
            
            if manager_type == "LightweightMemoryManager":
                # ê²½ëŸ‰ ë²„ì „ì€ ì§ì ‘ í˜¸ì¶œ
                logger.info("ğŸš‚ Railway ê²½ëŸ‰ memory_managerë¡œ íšŒìƒ")
                results = await self.memory_manager.recall_memories_async(query, limit)
                logger.info(f"âœ… ê²½ëŸ‰ memory_manager íšŒìƒ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                return results
            else:
                # ì „ì²´ ê¸°ëŠ¥ RecallEngine ì‚¬ìš©
                from aura_system.recall_engine import RecallEngine
                
                recall_engine = RecallEngine(self.memory_manager)
                context = {"user_id": user_id} if user_id else {}
                
                results = await recall_engine.recall(
                    query=query,
                    context=context,
                    limit=limit
                )
                
                logger.info(f"âœ… RecallEngine íšŒìƒ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                return results
            
        except Exception as e:
            logger.error(f"íšŒìƒ ì‹œìŠ¤í…œ ì‹¤íŒ¨: {e}")
            return await self._basic_recall(query, user_id, limit)
    
    async def _basic_recall(self, query: str, user_id: str = None, limit: int = 5):
        """ê¸°ë³¸ íšŒìƒ ê¸°ëŠ¥ (fallback)"""
        try:
            if not self.is_connected():
                return []
            
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê²€ìƒ‰
            search_filter = {}
            if user_id:
                search_filter["user_id"] = user_id
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
            keywords = query.lower().split()
            search_conditions = []
            
            for keyword in keywords:
                search_conditions.append({"content": {"$regex": keyword, "$options": "i"}})
            
            if search_conditions:
                search_filter["$or"] = search_conditions
            
            # ê²°ê³¼ ì¡°íšŒ
            results = list(self.memories.find(search_filter)
                          .sort("timestamp", -1)
                          .limit(limit))
            
            logger.info(f"âœ… ê¸°ë³¸ íšŒìƒ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            logger.error(f"ê¸°ë³¸ íšŒìƒ ì‹¤íŒ¨: {e}")
            return []
    
    async def recall_learned_content(self, query: str, user_id: str = None, limit: int = 5):
        """í•™ìŠµëœ ì½˜í…ì¸  íšŒìƒ (ë¬¸ì„œ ê¸°ë°˜)"""
        try:
            if not self.is_connected():
                return []
            
            # ë¬¸ì„œ íƒ€ì… í•„í„°
            search_filter = {"memory_type": "document_chunk"}
            if user_id:
                search_filter["user_id"] = user_id
            
            # í‚¤ì›Œë“œ ê²€ìƒ‰
            keywords = query.lower().split()
            search_conditions = []
            
            for keyword in keywords:
                search_conditions.append({"content": {"$regex": keyword, "$options": "i"}})
                search_conditions.append({"metadata.filename": {"$regex": keyword, "$options": "i"}})
            
            if search_conditions:
                search_filter["$or"] = search_conditions
            
            # ê²°ê³¼ ì¡°íšŒ
            results = list(self.memories.find(search_filter)
                          .sort("timestamp", -1)
                          .limit(limit))
            
            logger.info(f"âœ… í•™ìŠµëœ ì½˜í…ì¸  íšŒìƒ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            logger.error(f"í•™ìŠµëœ ì½˜í…ì¸  íšŒìƒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_memory_manager_status(self):
        """memory_manager ìƒíƒœ í™•ì¸"""
        if not self.memory_manager:
            return {"status": "not_initialized", "available": False}
        
        return {
            "status": "initialized" if self.memory_manager.is_initialized else "not_initialized",
            "available": self.memory_manager.is_initialized,
            "class": str(type(self.memory_manager).__name__)
        }
    
    async def cleanup_old_memories(self, user_id: str, days: int = 365):
        """ì˜¤ë˜ëœ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days)
            
            # ì˜¤ë˜ëœ ë©”ëª¨ë¦¬ ì‚­ì œ
            result = self.memories.delete_many({
                "user_id": user_id,
                "timestamp": {"$lt": cutoff_date},
                "importance_score": {"$lt": 0.5}  # ì¤‘ìš”ë„ê°€ ë‚®ì€ ë©”ëª¨ë¦¬ë§Œ
            })
            
            logger.info(f"ì˜¤ë˜ëœ ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ - ì‚¬ìš©ì: {user_id}, ì‚­ì œëœ ë©”ëª¨ë¦¬: {result.deleted_count}ê°œ")
            return {"deleted_count": result.deleted_count}
            
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return {"error": str(e)}

# ì „ì—­ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ (ì§€ì—° ì´ˆê¸°í™”)
memory_system = None

def get_eora_memory_system():
    """EORA ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜ (ì§€ì—° ì´ˆê¸°í™”)"""
    global memory_system
    if memory_system is None:
        memory_system = EORAMemorySystem()
    return memory_system 