#!/usr/bin/env python3
"""
ê°•í™”ëœ í•™ìŠµ ì‹œìŠ¤í…œ
- ì¹´í…Œê³ ë¦¬ë³„ í•™ìŠµ (ì˜ì—…ì‹œê°„, ìƒë‹´ë‚´ìš©, ì‹¬ë¦¬ìƒë‹´, ëª…ìƒ ë“±)
- 500~1000ì ì²­í¬ ë¶„í• 
- DB ë°˜ì˜ í™•ì¸
- ìƒì„¸ ë¡œê·¸ ë° ë””ë²„ê·¸ ì •ë³´
"""

import logging
import re
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
from pymongo import MongoClient
from bson import ObjectId

logger = logging.getLogger(__name__)

class EnhancedLearningSystem:
    """ê°•í™”ëœ í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self, mongo_client=None):
        self.mongo_client = mongo_client
        self.db = None
        if mongo_client is not None:
            try:
                # mongo_clientê°€ ì´ë¯¸ Database ê°ì²´ì¸ ê²½ìš°ì™€ Client ê°ì²´ì¸ ê²½ìš° êµ¬ë¶„
                if hasattr(mongo_client, 'list_collection_names'):
                    # ì´ë¯¸ Database ê°ì²´
                    self.db = mongo_client
                else:
                    # Client ê°ì²´ì¸ ê²½ìš° eora_ai ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©
                    self.db = mongo_client["eora_ai"]
            except Exception as e:
                logger.warning(f"ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ì‹¤íŒ¨: {e}")
                self.db = None
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì •ì˜
        self.category_keywords = {
            "ì˜ì—…ì‹œê°„": ["ì˜ì—…ì‹œê°„", "ìš´ì˜ì‹œê°„", "ì˜¤í”ˆì‹œê°„", "ë§ˆê°ì‹œê°„", "íœ´ë¬´ì¼", "í‰ì¼", "ì£¼ë§", "ê³µíœ´ì¼"],
            "ìƒë‹´ë‚´ìš©": ["ìƒë‹´", "ë¬¸ì˜", "ê³ ê°ì„œë¹„ìŠ¤", "ê³ ê°ì§€ì›", "ìƒë‹´ì‹œê°„", "ìƒë‹´ê°€ëŠ¥"],
            "ì‹¬ë¦¬ìƒë‹´": ["ì‹¬ë¦¬", "ìƒë‹´", "ì¹˜ë£Œ", "ìŠ¤íŠ¸ë ˆìŠ¤", "ë¶ˆì•ˆ", "ìš°ìš¸", "íŠ¸ë¼ìš°ë§ˆ", "ì •ì‹ ê±´ê°•"],
            "ëª…ìƒ": ["ëª…ìƒ", "ë§ˆìŒì±™ê¹€", "í˜¸í¡", "ìš”ê°€", "ëª…ìƒë²•", "ëª…ìƒë°©ë²•", "ë§ˆìŒìˆ˜ë ¨"],
            "ì¼ë°˜": ["ì¼ë°˜", "ê¸°íƒ€", "ê¸°ë³¸"]
        }
    
    async def learn_document(self, content: str, filename: str, category: str = None, user_id: str = "admin", is_admin_learning: bool = True) -> Dict[str, Any]:
        """ë¬¸ì„œ í•™ìŠµ ì²˜ë¦¬"""
        logger.info("="*60)
        logger.info(f"ğŸ“š ê°•í™”ëœ í•™ìŠµ ì‹œì‘: {filename}")
        logger.info(f"ğŸ“‹ ì¹´í…Œê³ ë¦¬: {category or 'ìë™ê°ì§€'}")
        logger.info("="*60)
        
        try:
            # 1ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€
            if not category:
                category = self._detect_category(content)
                logger.info(f"ğŸ” ìë™ ê°ì§€ëœ ì¹´í…Œê³ ë¦¬: {category}")
            
            # 2ë‹¨ê³„: í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í•  (500~1000ì)
            chunks = self._split_into_chunks(content)
            logger.info(f"âœ‚ï¸ ì²­í¬ ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ")
            
            # 3ë‹¨ê³„: DB ì €ì¥
            saved_memories = await self._save_to_database(chunks, filename, category, user_id, is_admin_learning)
            logger.info(f"ğŸ’¾ DB ì €ì¥ ì™„ë£Œ: {len(saved_memories)}ê°œ")
            
            # 4ë‹¨ê³„: DB ë°˜ì˜ í™•ì¸
            verification_results = await self._verify_database_save(saved_memories, chunks)
            
            # 5ë‹¨ê³„: ê²°ê³¼ ë°˜í™˜
            result = {
                "success": True,
                "filename": filename,
                "category": category,
                "total_chunks": len(chunks),
                "saved_memories": len(saved_memories),
                "db_verification": verification_results,
                "details": {
                    "original_length": len(content),
                    "avg_chunk_size": sum(len(c) for c in chunks) // len(chunks) if chunks else 0,
                    "min_chunk_size": min(len(c) for c in chunks) if chunks else 0,
                    "max_chunk_size": max(len(c) for c in chunks) if chunks else 0,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
            logger.info("="*60)
            logger.info("ğŸ‰ ê°•í™”ëœ í•™ìŠµ ì™„ë£Œ!")
            logger.info(f"ğŸ“ íŒŒì¼: {filename}")
            logger.info(f"ğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {category}")
            logger.info(f"âœ‚ï¸ ì²­í¬: {len(chunks)}ê°œ")
            logger.info(f"ğŸ’¾ ì €ì¥: {len(saved_memories)}ê°œ")
            logger.info("="*60)
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ê°•í™”ëœ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {
                "success": False,
                "error": str(e),
                "filename": filename
            }
    
    def _detect_category(self, content: str) -> str:
        """ë‚´ìš© ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ìë™ ê°ì§€"""
        content_lower = content.lower()
        
        for category, keywords in self.category_keywords.items():
            for keyword in keywords:
                if keyword in content_lower:
                    logger.info(f"ğŸ” ì¹´í…Œê³ ë¦¬ ê°ì§€: '{keyword}' -> {category}")
                    return category
        
        return "ì¼ë°˜"
    
    def _split_into_chunks(self, content: str, min_size: int = 500, max_size: int = 1000) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ 500~1000ì ì²­í¬ë¡œ ë¶„í• """
        logger.info(f"âœ‚ï¸ ì²­í¬ ë¶„í•  ì‹œì‘: {min_size}~{max_size}ì")
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', content)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            sentence_with_period = sentence + "."
            
            # ìµœì†Œ í¬ê¸°ë³´ë‹¤ ì‘ìœ¼ë©´ ê³„ì† ì¶”ê°€
            if len(current_chunk + sentence_with_period) < min_size:
                current_chunk += sentence_with_period
            # ìµœëŒ€ í¬ê¸°ë¥¼ ì´ˆê³¼í•˜ë©´ í˜„ì¬ ì²­í¬ ì €ì¥í•˜ê³  ìƒˆ ì²­í¬ ì‹œì‘
            elif len(current_chunk + sentence_with_period) > max_size:
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                    logger.info(f"âœ… ì²­í¬ {len(chunks)} ìƒì„±: {len(current_chunk)}ì")
                current_chunk = sentence_with_period
            # ì ì ˆí•œ í¬ê¸°ë©´ í˜„ì¬ ì²­í¬ì— ì¶”ê°€
            else:
                current_chunk += sentence_with_period
        
        # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
            logger.info(f"âœ… ë§ˆì§€ë§‰ ì²­í¬ {len(chunks)} ìƒì„±: {len(current_chunk)}ì")
        
        return chunks
    
    async def _save_to_database(self, chunks: List[str], filename: str, category: str, user_id: str = "admin", is_admin_learning: bool = True) -> List[str]:
        """ì²­í¬ë¥¼ DBì— ì €ì¥"""
        logger.info(f"ğŸ’¾ DB ì €ì¥ ì‹œì‘: {len(chunks)}ê°œ ì²­í¬")
        
        saved_ids = []
        # ë³´ì•ˆì„ ìœ„í•´ íŒŒì¼ëª… í•´ì‹± ì‚¬ìš©
        import hashlib
        filename_hash = hashlib.md5(filename.encode()).hexdigest()[:8]
        session_id = f"enhanced_learning_{filename_hash}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        if self.db is None:
            logger.error("âŒ DB ì—°ê²°ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            # ë°ì´í„°ë² ì´ìŠ¤ ì¬ì—°ê²° ì‹œë„
            try:
                from mongodb_config import get_optimized_database
                new_db = get_optimized_database()
                if new_db is None:
                    logger.error("âŒ DB ì¬ì—°ê²° ì‹¤íŒ¨")
                    return saved_ids
                
                # Database ê°ì²´ì¸ì§€ í™•ì¸
                if hasattr(new_db, 'list_collection_names'):
                    self.db = new_db
                    logger.info("âœ… DB ì¬ì—°ê²° ì„±ê³µ")
                else:
                    logger.error("âŒ ì¬ì—°ê²°ëœ ê°ì²´ê°€ Database íƒ€ì…ì´ ì•„ë‹˜")
                    return saved_ids
            except Exception as e:
                logger.error(f"âŒ DB ì¬ì—°ê²° ì˜ˆì™¸: {e}")
                return saved_ids
        
        try:
            # MongoDB ì»¬ë ‰ì…˜ ì ‘ê·¼ ì•ˆì „ì„± í™•ì¸
            try:
                memories_collection = self.db.memories
                # ì»¬ë ‰ì…˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                self.db.list_collection_names()
            except Exception as collection_error:
                logger.error(f"âŒ ì»¬ë ‰ì…˜ ì ‘ê·¼ ì‹¤íŒ¨: {collection_error}")
                return saved_ids
            
            for i, chunk in enumerate(chunks):
                # ê´€ë¦¬ì í•™ìŠµì¸ ê²½ìš° ê³µìœ  ë°ì´í„°ë¡œ ì €ì¥, ì•„ë‹Œ ê²½ìš° ê°œì¸ ë°ì´í„°ë¡œ ì €ì¥
                if is_admin_learning:
                    # ê´€ë¦¬ì í•™ìŠµ: ëª¨ë“  íšŒì›ì´ ì ‘ê·¼ ê°€ëŠ¥í•œ ê³µìœ  ë°ì´í„°
                    memory_doc = {
                        "user_id": "admin_shared",  # ê³µìœ  ë°ì´í„° ì‹ë³„ì
                        "session_id": session_id,
                        "message": f"[{category} í•™ìŠµìë£Œ {i+1}/{len(chunks)}] {filename}",
                        "response": chunk,
                        "content": chunk,  # EORAMemorySystem í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
                        "timestamp": datetime.now().isoformat(),
                        "memory_type": "enhanced_learning",
                        "category": category,
                        "importance": 0.9,
                        "tags": [category, "í•™ìŠµìë£Œ", "ê°•í™”í•™ìŠµ", filename.split('.')[0]],
                        "keywords": [category, "í•™ìŠµìë£Œ", "ê°•í™”í•™ìŠµ", filename.split('.')[0]],  # EORAMemorySystem í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
                        "source_file": filename,
                        "filename": filename,  # EORAMemorySystem í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
                        "chunk_index": i,
                        "chunk_size": len(chunk),
                        "source": "enhanced_learning",  # êµ¬ë¶„ì„ ìœ„í•œ ì†ŒìŠ¤ í‘œì‹œ
                        "admin_shared": True,  # ê´€ë¦¬ì ê³µìœ  í”Œë˜ê·¸
                        "shared_to_all": True,  # ì „ì²´ íšŒì› ê³µìœ  í”Œë˜ê·¸
                        "uploaded_by": user_id,  # ì‹¤ì œ ì—…ë¡œë” ì •ë³´
                        "upload_type": "admin_document"  # ê´€ë¦¬ì ë¬¸ì„œ íƒ€ì…
                    }
                else:
                    # ê°œì¸ í•™ìŠµ: ê°œì¸ ì „ìš© ë°ì´í„°
                    memory_doc = {
                        "user_id": user_id,
                        "session_id": session_id,
                        "message": f"[{category} í•™ìŠµìë£Œ {i+1}/{len(chunks)}] {filename}",
                        "response": chunk,
                        "content": chunk,  # EORAMemorySystem í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
                        "timestamp": datetime.now().isoformat(),
                        "memory_type": "enhanced_learning",
                        "category": category,
                        "importance": 0.9,
                        "tags": [category, "í•™ìŠµìë£Œ", "ê°•í™”í•™ìŠµ", filename.split('.')[0]],
                        "keywords": [category, "í•™ìŠµìë£Œ", "ê°•í™”í•™ìŠµ", filename.split('.')[0]],  # EORAMemorySystem í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
                        "source_file": filename,
                        "filename": filename,  # EORAMemorySystem í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
                        "chunk_index": i,
                        "chunk_size": len(chunk),
                        "source": "enhanced_learning",  # êµ¬ë¶„ì„ ìœ„í•œ ì†ŒìŠ¤ í‘œì‹œ
                        "admin_shared": False,  # ê°œì¸ ë°ì´í„°
                        "shared_to_all": False,  # ê°œì¸ ì „ìš©
                        "uploaded_by": user_id,  # ì—…ë¡œë” ì •ë³´
                        "upload_type": "personal_document"  # ê°œì¸ ë¬¸ì„œ íƒ€ì…
                    }
                
                result = memories_collection.insert_one(memory_doc)
                saved_ids.append(str(result.inserted_id))
                
                if (i+1) % 5 == 0:
                    logger.info(f"ğŸ’¾ ì €ì¥ ì§„í–‰: {i+1}/{len(chunks)} ì™„ë£Œ")
            
            logger.info(f"âœ… DB ì €ì¥ ì™„ë£Œ: {len(saved_ids)}ê°œ")
            return saved_ids
            
        except Exception as e:
            logger.error(f"âŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            return saved_ids
    
    async def _verify_database_save(self, saved_ids: List[str], chunks: List[str]) -> List[str]:
        """DB ì €ì¥ í™•ì¸"""
        logger.info("ğŸ” DB ì €ì¥ í™•ì¸ ì‹œì‘...")
        verification_results = []
        
        if self.db is None:
            verification_results.append("âš ï¸ DB ì—°ê²° ì—†ìŒ")
            return verification_results
        
        try:
            memories_collection = self.db.memories
            
            # ì €ì¥ëœ ë©”ëª¨ë¦¬ ì¡°íšŒ
            stored_memories = list(memories_collection.find(
                {"_id": {"$in": [ObjectId(id) for id in saved_ids]}},
                {"_id": 1, "message": 1, "response": 1, "content": 1, "category": 1, "chunk_index": 1}
            ))
            
            logger.info(f"ğŸ” DBì—ì„œ ì¡°íšŒëœ ë©”ëª¨ë¦¬: {len(stored_memories)}ê°œ")
            
            if len(stored_memories) == len(chunks):
                verification_results.append("âœ… ëª¨ë“  ì²­í¬ DB ì €ì¥ í™•ì¸")
                logger.info("âœ… DB ë°˜ì˜ ì„±ê³µ: ëª¨ë“  ì²­í¬ê°€ ì •ìƒì ìœ¼ë¡œ ì €ì¥ë¨")
            else:
                verification_results.append(f"âš ï¸ ë¶€ë¶„ ì €ì¥: {len(stored_memories)}/{len(chunks)}ê°œ")
                logger.warning(f"âš ï¸ DB ë°˜ì˜ ë¶€ë¶„ ì‹¤íŒ¨: ì˜ˆìƒ {len(chunks)}ê°œ, ì‹¤ì œ {len(stored_memories)}ê°œ")
            
            # ìƒ˜í”Œ ë©”ëª¨ë¦¬ í™•ì¸
            if stored_memories:
                sample = stored_memories[0]
                verification_results.append(f"âœ… ìƒ˜í”Œ ë©”ëª¨ë¦¬ í™•ì¸: ID={sample['_id']}, ì¹´í…Œê³ ë¦¬={sample.get('category', 'N/A')}")
                logger.info(f"ğŸ“ ìƒ˜í”Œ ë©”ëª¨ë¦¬: ID={sample['_id']}, ì¹´í…Œê³ ë¦¬={sample.get('category', 'N/A')}")
            
            return verification_results
            
        except Exception as e:
            logger.error(f"âŒ DB í™•ì¸ ì‹¤íŒ¨: {e}")
            verification_results.append(f"âŒ DB í™•ì¸ ì‹¤íŒ¨: {e}")
            return verification_results
    
    async def get_learning_stats(self) -> Dict[str, Any]:
        """í•™ìŠµ í†µê³„ ì¡°íšŒ"""
        if self.db is None:
            return {"error": "DB ì—°ê²° ì—†ìŒ"}
        
        try:
            memories_collection = self.db.memories
            
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            pipeline = [
                {"$match": {"memory_type": "enhanced_learning"}},
                {"$group": {
                    "_id": "$category",
                    "count": {"$sum": 1},
                    "total_size": {"$sum": {"$strLenCP": "$response"}}
                }}
            ]
            
            category_stats = list(memories_collection.aggregate(pipeline))
            
            # ì „ì²´ í†µê³„
            total_count = memories_collection.count_documents({"memory_type": "enhanced_learning"})
            
            return {
                "total_learning_memories": total_count,
                "category_stats": category_stats,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ í•™ìŠµ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
enhanced_learning_system = None

def get_enhanced_learning_system(mongo_client=None):
    """ê°•í™”ëœ í•™ìŠµ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global enhanced_learning_system
    if enhanced_learning_system is None:
        enhanced_learning_system = EnhancedLearningSystem(mongo_client)
    return enhanced_learning_system 