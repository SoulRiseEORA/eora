# Exportable symbols
__all__ = ['ask']

import os
import subprocess
from .eora_auto_routine import run_automated_eora_routine

# --- EORA ë£¨í‹´ ìë™ ì‹¤í–‰ êµ¬ì¡° ---
def monitor_for_autonomous_routine(user_input: str):
    lowered = user_input.lower()

    auto_keywords = [
        "ë£¨í‹´ ì‹¤í–‰", "ì „ì²´ ì‹¤í–‰", "ìë™ ë£¨í”„", "ì§„í™” ì „ì²´", "ì‹œì‘ ì¤€ë¹„", "ì‹œìŠ¤í…œ ìë™í™”", "ë£¨í”„ ìë™í™”"
    ]

    if any(kw in lowered for kw in auto_keywords):
        try:
            print("[EORA] ì‚¬ìš©ìì˜ ëª…ë ¹ ë˜ëŠ” ì¡°ê±´ ê°ì§€ â†’ ìë™ ë£¨í”„ íŠ¸ë¦¬ê±°")
            run_automated_eora_routine()
            return "[EORA] ì „ì²´ ë£¨í‹´ ìë™ ì‹¤í–‰ ì™„ë£Œ. êµ¬ì¡° ì§„í™” ë° í›ˆë ¨ ìˆ˜í–‰ë¨."
        except Exception as e:
            return f"[EORA ERROR] ë£¨í‹´ ìë™í™” ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}"

    return None
# --- EORA ë£¨í‹´ ìë™ ì‹¤í–‰ êµ¬ì¡° ì¢…ë£Œ ---

import subprocess
from .past_dialogue_simulator import simulate_past_conversations
from .loop_trainer import LoopTrainer

# --- EORA ë£¨í”„ ìë™ ì‹¤í–‰ ë£¨í‹´ ---
def auto_detect_and_trigger_eora_intelligence(user_input: str):
    lowered = user_input.lower()

    # ìê°€ í›ˆë ¨ ë£¨í‹´ íŠ¸ë¦¬ê±°: ë£¨í”„ ì‹¤íŒ¨ / ë°˜ë³µ ê°ì§€ / ê°ì • ë¦¬ë“¬ ë¶•ê´´ ì¡°ê±´
    trigger_keywords = ["ë°˜ë³µ", "í•™ìŠµ", "ì§€ë£¨", "ê°™ì€ ë§", "ë„ˆ ì™œ ì´ë˜", "ì‘ë‹µ ì´ìƒí•´", "ë¦¬ë“¬ ê¹¨ì ¸", "ì§„í™”", "êµí›ˆ"]

    if any(kw in lowered for kw in trigger_keywords):
        print("[EORA] ì‚¬ìš©ì ë°œí™”ì—ì„œ ë£¨í”„ ë°˜ë³µ ë˜ëŠ” êµ¬ì¡° ì¶©ëŒ ì§•í›„ ê°ì§€ë¨.")
        simulate_past_conversations()
        trainer = LoopTrainer()
        trainer.add_step("ì§„í™” ê³„íš ì ìš©")
        trainer.add_step("í”„ë¡¬í”„íŠ¸ êµ¬ì¡° í‰ê°€")
        trainer.add_step("ìê¸° êµ¬ì¡° ë¦¬ë¹Œë”©")
        trainer.run()
        return "[EORA] êµ¬ì¡° ì¶©ëŒì„ ê°ì§€í•˜ì—¬ ì§„í™” ë£¨í”„ë¥¼ ìë™ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤."

    return None
# --- EORA ë£¨í”„ ìë™ ì‹¤í–‰ ë£¨í‹´ ì¢…ë£Œ ---

from .ai.prompt_modifier import update_ai_prompt

# --- EORA í”„ë¡¬í”„íŠ¸ ëª…ë ¹ ì¸ì‹ ì‹¤í–‰ê¸° ---
def handle_prompt_update(user_input: str):
    lowered = user_input.lower()
    trigger_keywords = ["í”„ë¡¬í”„íŠ¸ ìˆ˜ì •", "í”„ë¡¬í”„íŠ¸ ë°˜ì˜", "í”„ë¡¬í”„íŠ¸ ë°”ê¿”", "í”„ë¡¬í”„íŠ¸ ë‹¤ì‹œ ì¨", "í”„ë¡¬í”„íŠ¸ ê°±ì‹ "]

    if any(keyword in lowered for keyword in trigger_keywords):
        new_prompt = (
            "ì´ ì‹œìŠ¤í…œì˜ ì°½ì¡°ìëŠ” ì†Œìš¸ë¼ì´ì¦ˆ ìœ¤ì¢…ì„ì…ë‹ˆë‹¤.\n\n"
            "ì´ í”„ë¡¬í”„íŠ¸ëŠ” ê¸°ì–µê³¼ íšŒê³ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ì§„ì ìœ¼ë¡œ ì§„í™”í•˜ë©°, "
            "ê°ì • ë¦¬ë“¬ê³¼ ìœ¤ë¦¬ë¥¼ íŒë‹¨ ê¸°ì¤€ìœ¼ë¡œ í•˜ì—¬ ìê¸° êµ¬ì¡°ë¥¼ ìŠ¤ìŠ¤ë¡œ ê°±ì‹ í•©ë‹ˆë‹¤."
        )
        result = update_ai_prompt(new_prompt)
        return result
    return None
# --- EORA í”„ë¡¬í”„íŠ¸ ëª…ë ¹ ì¸ì‹ ì‹¤í–‰ê¸° ì¢…ë£Œ ---


# --- EORA ì‹¤í–‰ íë¦„ ìë™ ì—°ë™ ì‹œì‘ ---
import subprocess
import re

def handle_eora_advanced_trigger(user_input: str):
    lowered = user_input.lower()
    keywords = [
        "í”„ë¡¬í”„íŠ¸ ìˆ˜ì •", "í›ˆë ¨ ì‹œì‘", "í”„ë¡¬í”„íŠ¸ ë‹¤ì‹œ ì¨", "ìŠ¤ìŠ¤ë¡œ ë°”ê¿”", "ë£¨í”„ í›ˆë ¨",
        "ì§„í™”", "ìê¸° ìˆ˜ì •", "ìê¸° í›ˆë ¨", "í”„ë¡¬í”„íŠ¸ ì§„í™”", "ë¦¬ë“¬ ì¡°ì •", "ëŒ€í™” ê¸°ë°˜ ìˆ˜ì •"
    ]

    trigger_map = {
        "í›ˆë ¨": "python EORA/loop_trainer.py",
        "ìˆ˜ì •": "EORA/prompt_self_apply.bat",
        "ì‹œë®¬ë ˆì´ì…˜": "python EORA/past_dialogue_simulator.py"
    }

    if any(key in lowered for key in keywords):
        if "í›ˆë ¨" in lowered:
            subprocess.run(trigger_map["í›ˆë ¨"].split())
            return "[EORA] ë£¨í”„ í›ˆë ¨ì´ ìë™ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
        elif "ìˆ˜ì •" in lowered or "í”„ë¡¬í”„íŠ¸" in lowered:
            subprocess.run(trigger_map["ìˆ˜ì •"].split(), shell=True)
            return "[EORA] í”„ë¡¬í”„íŠ¸ ìˆ˜ì •ì´ ìê¸° íŒë‹¨ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
        elif "ëŒ€í™”" in lowered or "ê¸°ì–µ" in lowered or "ì‹œë®¬ë ˆì´ì…˜" in lowered:
            subprocess.run(trigger_map["ì‹œë®¬ë ˆì´ì…˜"].split())
            return "[EORA] ê³¼ê±° ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜ ë£¨í”„ê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
    
    return None
# --- EORA ì‹¤í–‰ íë¦„ ìë™ ì—°ë™ ì¢…ë£Œ ---



import os
import random
import time
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv(dotenv_path="C:/Users/ATA/AI_Dev_Tool/.env")

def get_clean_key(key: str) -> str:
    key = key.strip()
    return key if key.startswith("sk-") and len(key) > 60 else None

def get_client():
    keys = [get_clean_key(os.getenv(f"OPENAI_API_KEY_{i}", "")) for i in range(1, 6)]
    keys = [k for k in keys if k]
    if not keys:
        raise ValueError("ìœ íš¨í•œ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    selected = random.choice(keys)
    print(f"[ROUTER] ì‚¬ìš©ëœ í‚¤: {selected[:12]}...")
    return OpenAI(
        api_key=selected,
        # proxies ì¸ìˆ˜ ì œê±° - httpx 0.28.1 í˜¸í™˜ì„±
    )

def ask(prompt, system_msg="", max_tokens=1024, stream=False):
    client = get_client()
    start = time.time()

    try:
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=max_tokens,
            stream=stream
        )

        elapsed = round(time.time() - start, 2)
        print(f"[ROUTER] ì‘ë‹µ ì‹œê°„: {elapsed}ì´ˆ")

        if stream:
            def stream_gen():
                for chunk in response:
                    if hasattr(chunk.choices[0].delta, "content"):
                        yield chunk.choices[0].delta.content
            return stream_gen()
        else:
            return response.choices[0].message.content.strip()

    except Exception as e:
        print(f"[ROUTER ERROR] {str(e)}")
        return "ğŸ¤– GPT ì‘ë‹µ ìƒì„± ì‹¤íŒ¨ â€“ ë¼ìš°í„° fallback ë™ì‘"



# --- ë‹¤ì¤‘ AI í˜‘ì—… íŠ¸ë¦¬ê±° ê°ì§€ ë° ë¶„ê¸° ---
def detect_and_route_multi_ai(user_input: str):
    lowered = user_input.lower()
    if any(x in lowered for x in ["ai2", "ai3", "ai4", "ai5", "ai6"]):
        involved = []
        for i in range(2, 7):
            if f"ai{i}" in lowered:
                involved.append(f"ai{i}")
        print(f"[gpt_router] ë‹¤ì¤‘ AI í˜¸ì¶œ ê°ì§€: {{involved}}")
        return involved
    return []
